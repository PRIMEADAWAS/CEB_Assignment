{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRIMEADAWAS/CEB_Assignment/blob/main/LlamaIndex101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OSJOuyTEQ3U",
        "outputId": "e57e2dc4-0f47-4fa8-d0a0-0a155af905ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=sk-YOUR_API_KEY\n"
          ]
        }
      ],
      "source": [
        "%set_env OPENAI_API_KEY=YOUR_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaxmzHxGEQ3Y"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQo7MHZhEQ3Y"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-openai\n",
        "!pip install llama-index-llms-openai-like\n",
        "!pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "id": "-gRPKL2EFsVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "rX7_zRuoUgXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlSCmLQgEQ3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef6b9aa-d032-4f73-9e6b-bc27d6601d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk is a billionaire entrepreneur and CEO of multiple companies, including Tesla, SpaceX, Neuralink, and The Boring Company. He is known for his ambitious vision for the future, including colonizing Mars, developing sustainable energy solutions, and advancing artificial intelligence. Musk is also known for his outspoken and sometimes controversial statements on social media.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model = 'gpt-3.5-turbo',temperature=0.1,max_tokens=100)\n",
        "response = llm.complete(\"who is elon musk\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging face"
      ],
      "metadata": {
        "id": "Qs6tnBL9N_uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "Eh5nFJR4OFU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import (\n",
        "    HuggingFaceInferenceAPI,\n",
        "    HuggingFaceLLM,\n",
        ")\n",
        "HF_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")"
      ],
      "metadata": {
        "id": "oYBKWY1SNdJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remotely_run = HuggingFaceInferenceAPI(\n",
        "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\", token=HF_TOKEN\n",
        ")\n",
        "# remotely_run_anon = HuggingFaceInferenceAPI(\n",
        "#     model_name=\"HuggingFaceH4/zephyr-7b-alpha\"\n",
        "# )"
      ],
      "metadata": {
        "id": "3aPBlUPkOQOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f08163-e19c-4196-97d9-a740572a1bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion_response = remotely_run.complete(\"To infinity, and\")\n",
        "print(completion_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUrrltP4OhAo",
        "outputId": "4847a00f-1aaa-4c95-b7fe-9dd479d37b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " beyond!\n",
            "\n",
            "The Toy Story franchise has been a beloved part of pop culture for over two decades, and it's not slowing down anytime soon. The latest installment, Toy Story 4, is set to hit theaters this summer, and it's already generating buzz.\n",
            "\n",
            "The movie follows the adventures of Woody, Buzz, and the gang as they embark on a new adventure with a new toy, Forky. The trailer for the movie has been released, and it's already getting fans excited for the film.\n",
            "\n",
            "One of the most exciting things about Toy Story 4 is the return of some beloved characters. Bo Peep, who was last seen in Toy Story 2, is back and looking better than ever. She's now a modern, independent woman, and her new look has been getting a lot of attention.\n",
            "\n",
            "Another exciting addition to the movie is the introduction of new characters, including Forky, who is voiced by Tony Hale. Forky is a spork with a popsicle stick for a handle, and he's not exactly thrilled about being a toy.\n",
            "\n",
            "The trailer for Toy Story 4 has been viewed over 10 million\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RVWCnPXEQ3c"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-embeddings-instructor"
      ],
      "metadata": {
        "id": "KyANA1QwRDTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkPepgHrEQ3d",
        "outputId": "d67481e1-e31b-4a4b-daa9-519a498a5727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "[0.03607286512851715, -0.0005120203131809831, -0.03582380712032318, -0.03432123363018036, 0.010324924252927303, -0.02194463461637497, -0.044648975133895874, 0.04291066527366638, 0.04395976662635803, -0.015890754759311676]\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\").get_text_embedding(\"Hello World!\")\n",
        "print(len(embed_model))\n",
        "print(embed_model[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "print(len(embeddings))\n",
        "print(embeddings[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOuXX7fLRPAG",
        "outputId": "7e74bf9f-244a-4637-dbd5-829f544f4a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n",
            "[-0.003275663824751973, -0.011690725572407246, 0.04155917093157768, -0.03814810514450073, 0.02418305166065693, 0.013644285500049591, 0.0111179044470191, 0.04811961576342583, 0.02140955626964569, 0.014174910262227058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading"
      ],
      "metadata": {
        "id": "DOttCBP5pNRi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNqkdDB3FCyS"
      },
      "source": [
        "## Reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLjTY340FCyW"
      },
      "source": [
        "### HTMLNodeParser\n",
        "can set specific tags"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```html\n",
        "<html>\n",
        "  <head>\n",
        "      <title>Mockup Data</title>\n",
        "  </head>\n",
        "  <body>  \n",
        "      <h1>Say Hello</h1>\n",
        "      <h2>Say World</h2>\n",
        "      <h3>Say !</h3>\n",
        "      <pre>\n",
        "          <code>\n",
        "              print(\"Hello World!\")\n",
        "          </code>\n",
        "      </pre>\n",
        "  </body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "1Husgb0y3JbR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV8apm3qFCyW",
        "outputId": "d50dab95-b840-45be-db7a-392763d83232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Say Hello\n",
            "1 Say World\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import HTMLNodeParser\n",
        "\n",
        "html_docs = FlatReader().load_data(Path(\"./MockupData/data.html\"))\n",
        "parser = HTMLNodeParser(tags=['h1','h2'])  # optional list of tags\n",
        "# parser = HTMLNodeParser()\n",
        "html_nodes = parser.get_nodes_from_documents(html_docs)\n",
        "\n",
        "for idx,i in enumerate(html_nodes) :\n",
        "    print(idx,i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro-q0imAFCyX"
      },
      "source": [
        "### JSONNodeParser\n",
        "nested cannot read"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```json\n",
        "{\n",
        "    \"h1\" : \"Say Hello\",\n",
        "    \"h2\" : \"Say World\",\n",
        "    \"h3\" : \"Say !\",\n",
        "    \"code\" : \"print(\\\"Hello World!\\\")\",\n",
        "    \"nested\" : {\n",
        "        \"nest_h1\" : \"Nested Hello\",\n",
        "        \"nest_h2\" : \"Nested World\",\n",
        "        \"nest_h3\" : \"Nested !\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "zrgB5Izg3UFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4jHR81LFCyX",
        "outputId": "22c9680e-af00-4505-de5b-e567c4e29fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Say Hello\n",
            "1 Say World\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import JSONNodeParser\n",
        "\n",
        "json_docs = FlatReader().load_data(Path(\"./MockupData/data.json\"))\n",
        "parser = JSONNodeParser()\n",
        "json_nodes = parser.get_nodes_from_documents(json_docs)\n",
        "for idx,i in enumerate(html_nodes) :\n",
        "    print(idx,i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-ML6PJBFCyY"
      },
      "source": [
        "### MarkdownNodeParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHN_UuzsFCyY",
        "outputId": "e5ff0ef8-001e-43b4-d98c-7949c99dbb5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 H1 Say Hello\n",
            "1 H2 Say World\n",
            "2 H3 Say !\n",
            "\n",
            "```\n",
            "print(\"Hello World!\")\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import MarkdownNodeParser\n",
        "\n",
        "markdown_docs = FlatReader().load_data(Path(\"./MockupData/data.md\"))\n",
        "parser = MarkdownNodeParser()\n",
        "markdown_nodes = parser.get_nodes_from_documents(markdown_docs)\n",
        "for idx,i in enumerate(markdown_nodes) :\n",
        "    print(idx,i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkkR2foL1Zz3"
      },
      "source": [
        "### SimpleFileNodeParser\n",
        "auto detect file type by extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "753c029d-f0f4-4bd6-8a6e-3e039bba006b",
        "id": "S5mCmHRn1Zz4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/maatick/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 H1 Say Hello\n",
            "1 H2 Say World\n",
            "2 H3 Say !\n",
            "\n",
            "```\n",
            "print(\"Hello World!\")\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SimpleFileNodeParser\n",
        "from llama_index.readers.file import FlatReader\n",
        "from pathlib import Path\n",
        "\n",
        "md_docs = FlatReader().load_data(Path(\"./MockupData/data.md\"))\n",
        "\n",
        "parser = SimpleFileNodeParser()\n",
        "md_nodes = parser.get_nodes_from_documents(md_docs)\n",
        "for idx,i in enumerate(md_nodes):\n",
        "    print(idx,i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNixfaNlFCyY"
      },
      "source": [
        "### DatabaseReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv2WUQtAFCyY"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.database import DatabaseReader\n",
        "db = DatabaseReader(\n",
        "    scheme=\"postgresql\",  # Database Scheme\n",
        "    host=\"test.supabase.com\",  # Database Host\n",
        "    port=\"8000\",  # Database Port\n",
        "    user=\"test.postgres\",  # Database User\n",
        "    password=\"your_password\",  # Database Password\n",
        "    dbname=\"postgres\",  # Database Name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klgNf0rxFCyZ",
        "outputId": "f529924e-ce32-47c6-d94b-e89f81410825"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id_='08d7034a-e88b-4154-a104-da822e110386', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='id: 1, created_at: 2024-02-21 13:02:31.445522+00:00, first_name: Bob, last_name: Malay', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f505869a-aabd-4c4b-9231-48c7320a4774', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='id: 2, created_at: 2024-02-21 13:02:42.008095+00:00, first_name: Alice, last_name: Layla', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ff47f1ce-fd5b-47f7-84b7-0f623a5a1fae', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='id: 3, created_at: 2024-02-21 13:03:02.936948+00:00, first_name: Casie, last_name: Lu', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.load_data('SELECT * FROM person')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEJ6XDlPE5ar"
      },
      "source": [
        "## Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QY_UCD2E5at",
        "outputId": "2ee5efb2-b0ae-4ae1-f9d6-efcf376083a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc ID: 320dba3e-6b2f-4033-adc7-4a7130304acb\n",
            "Text: Hello\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "document = Document(text = \"Hello\")\n",
        "print(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pcIDRdqE5av",
        "outputId": "84e3b7d6-1f59-4e63-f0bc-82fd8a0874fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator', 'class_name'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "document.to_dict().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bLGPxi2E5aw"
      },
      "source": [
        "## MetaData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um_wC-9oE5aw"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Document\n",
        "document_without_meta_data = Document(text = \"Hello\")\n",
        "document_with_meta_data = Document(text = \"Hello\", metadata = {\"language\": \"EN\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VXdjOunE5aw",
        "outputId": "71481933-7951-4f9e-b7c2-0cd17613d31b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "{'language': 'EN'}\n"
          ]
        }
      ],
      "source": [
        "print(document_without_meta_data.metadata)\n",
        "print(document_with_meta_data.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM metadata"
      ],
      "metadata": {
        "id": "6Y2Z1SY_tl1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIsCB3NbE5ax",
        "outputId": "c3c11ca7-8a0a-45dd-e4cd-3d1cc180d19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "--------\n",
            "language: EN\n",
            "\n",
            "Hello\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.schema import MetadataMode\n",
        "print(document_without_meta_data.get_content(MetadataMode.LLM))\n",
        "print('--------')\n",
        "print(document_with_meta_data.get_content(MetadataMode.LLM))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding metadata"
      ],
      "metadata": {
        "id": "UAdpAIjmttNB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2LHV61BE5ax",
        "outputId": "3101aaa1-7825-4e1c-fe33-9dbf5a7940c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "--------\n",
            "language: EN\n",
            "\n",
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(document_without_meta_data.get_content(MetadataMode.EMBED))\n",
        "print('--------')\n",
        "print(document_with_meta_data.get_content(MetadataMode.EMBED))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excluded metadata keys"
      ],
      "metadata": {
        "id": "1W96vRdYtcma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "049Y9ewbE5ay"
      },
      "outputs": [],
      "source": [
        "document_with_meta_data.excluded_llm_metadata_keys = [\"language\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T1fe1N5E5ay",
        "outputId": "141f050a-5bbf-40dd-82c1-10f00e76e36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "--------\n",
            "language: EN\n",
            "\n",
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(document_with_meta_data.get_content(MetadataMode.LLM))\n",
        "print('--------')\n",
        "print(document_with_meta_data.get_content(MetadataMode.EMBED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI2X2gynE5az",
        "outputId": "cc90ed6f-6c67-42af-f477-24b388839271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LLM sees this: \n",
            " Metadata: category=>finance, author=>LlamaIndex\n",
            "-----\n",
            "Content: This is a super-customized document\n",
            "The Embedding model sees this: \n",
            " Metadata: file_name=>super_secret_document.txt, category=>finance, author=>LlamaIndex\n",
            "-----\n",
            "Content: This is a super-customized document\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.core.schema import MetadataMode\n",
        "\n",
        "document = Document(\n",
        "    text=\"This is a super-customized document\",\n",
        "    metadata={\n",
        "        \"file_name\": \"super_secret_document.txt\",\n",
        "        \"category\": \"finance\",\n",
        "        \"author\": \"LlamaIndex\",\n",
        "    },\n",
        "    excluded_llm_metadata_keys=[\"file_name\"],\n",
        "    metadata_seperator=\", \",\n",
        "    metadata_template=\"{key}=>{value}\",\n",
        "    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The LLM sees this: \\n\",\n",
        "    document.get_content(metadata_mode=MetadataMode.LLM),\n",
        ")\n",
        "print(\n",
        "    \"The Embedding model sees this: \\n\",\n",
        "    document.get_content(metadata_mode=MetadataMode.EMBED),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edai5XUOE99j"
      },
      "source": [
        "## Transformation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "metadata": {
        "id": "1NLigSN_y1t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpM_-WJtE99n"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"II FinOps ?\n",
        "A FinOps (cloud Financial Operations)\n",
        "FinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\n",
        "\n",
        "B History\n",
        "FinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\n",
        "III Cloud in real life\n",
        "การใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\n",
        "A Spending decision\n",
        "ความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud environment เรียบร้อยแล้ว คนที่เข้าใจ Cloud มากที่สุดกลับเป็นทีม Engineer ที่ไม่มีหน้าที่ในการรับผิดชอบการใช้จ่ายของบริษัท หรือเมื่อ Spending decision ยังอยู่กับทีม Financial คนที่ต้อง Commit รายจ่ายของ Cloud computing ก็ยังคงเป็นทีม Engineer\n",
        "\n",
        "ถ้าไม่แก้ไขปัญหาจากเหตุการณ์ดังกล่าวจะเกิดเหตุการณ์ Engineer Commit รายจ่ายให้สูงเกินความจำเป็น หรือ การใช้งานบางอย่าง (Serverless) ส่งผลให้เกิดรายจ่ายที่ผิดปกติในเดือนนั้น ๆ โดยไม่ทราบสาเหตุ\n",
        "\n",
        "วิธีแก้ไขของหลายบริษัทคือการให้ Engineer ลดรายจ่ายให้อยู่ในเพดานที่เหมาะสม\n",
        "\n",
        "อ่านดูแล้วอาจเป็นวิธีการแก้ปัญหาที่ตรงจุด แต่วิธีดังกล่าวกลับเหมาะสมกับบริบทดั้งเดิม ไม่สมเหตุสมผลกับบริบทปัจจุบัน เพราะการกระจายอำนาจตัดสินใจให้กับทีมอื่นได้นั้นถือเป็นความสามารถที่ไม่เคยเกิดขึ้นมาก่อนและยังสอดคล้องกับการทำงานยุคใหม่ที่ใช้ Framework อย่างเช่น Agile ที่ต้องการให้เกิดความรวดเร็วในการตัดสินใจ\n",
        "\n",
        "B Variable spending\n",
        "การใช้งานบางบริษัทของผู้ให้บริการ Cloud computing ไม่ได้คิดค่าบริการตามจำนวนชั่วโมงที่ใช้งานอย่างที่เราเข้าใจ แต่การคิดค่าบริการอาจคิดจากจำนวนการเรียกใช้งานหรือจำนวนของ bandwidth เป็นต้น\n",
        "\n",
        "ลักษณะการคิดค่าบริการดังกล่าวมีข้อดีคือเป็นการคิดค่าใช้จ่ายแบบ Variable cost เราสามารถนำไปใช้ในการคำนวณหา Cost Of Goods Sold (COGS) ได้ทันที\n",
        "\n",
        "ส่วนข้อเสียคือถ้าทีม Financial ไม่เข้าใจที่มาของต้นทุนดังกล่าวแล้วไม่ได้ลงไว้ใน Variable cost หรือ COGS จะเกิดคำถามว่าทำไมค่าใช้จ่าย Cloud computing ในแต่ละเดือนนั้น ไม่เท่ากันและไม่สามารถพิจารณาค่าใช้จ่าย Cloud computing ล่วงหน้า\n",
        "\n",
        "วิธีแก้ไขของหลายบริษัทคือไม่ใช้งาน Cloud computing ในส่วน Variable cost หรือไม่ต้องใช้งาน Cloud ไปเลย\n",
        "\n",
        "C Scalable resource\n",
        "การปรับจำนวนทรัพยากรได้ตลอดเวลานั้นสามารถส่งเสริมให้เกิดนวัตกรรมได้ตลอดเวลา เนื่องจากทีม Engineer สามารถเข้าถึงทรัพยากรได้อย่างรวดเร็วและเข้าถึงบางทรัพยากรที่ไม่เคยมีมาก่อน เช่น การเข้าถึง High performance computer, การเข้าถึง Computer cluster เป็นต้น สิ่งเหล่านี้จะทำให้ทีม Engineer สามารถทดลองนวัตกรรมใหม่ ๆ หรือสำรวจความเป็นไปได้ใหม่ ๆ โดยปราศจากข้อจำกัดด้านการจัดซื้อ\n",
        "\n",
        "แต่ข้อเสียที่เกิดขึ้นเมื่อทีม Engineer สามารถเข้าถึงทรัพยากรเหล่านี้ได้โดยปราศจากการอนุมัติจากทีม Finance บางครั้งทีม Engineer อาจจะลืมหรือละเลยการใช้งานทรัพยากรเหล่านี้โดยเปิดทิ้งไว้ตลอดเวลา แต่ใช้งานจริงแค่เพียง 1% ของเวลาที่คิดค่าใช้จ่าย  ทำให้เกิดค่าใช้จ่ายส่วนเกินที่ไม่ควรเกิดขึ้น\n",
        "\n",
        "ดังนั้นเพื่อเป็นการป้องกันปัญหาดังกล่าวจำเป็นต้องให้เกิดการตรวจสอบการใช้งานได้ตลอดเวลา เพื่อติดตามและป้องกันไม่ให้เกิดปัญหาดังกล่าว\n",
        "\n",
        "VII  FinOps framework ถูกสร้างขึ้นมาโดยมีหัวข้อหลักทั้งหมด 5 หัวข้อ ดังนี้\n",
        "Maturity\n",
        "Principles\n",
        "Personas\n",
        "Phases\n",
        "Domains\n",
        "โดยแต่ละหัวข้อจะอธิบายถึงสถานะ, เครื่องมือ, กิจกรรม, ความเข้ากันได้ หรือ สิ่งขับเคลื่อน ซึ่งแต่ละหัวข้อสามารถแยกพิจารณาเมื่อไหร่ก็ได้ ไม่จำเป็นต้องเรียงลำดับและในแต่ละบริษัทไม่จำที่จะต้องให้น้ำหนักกับแต่ละหัวข้อเหมือนกันทุกบริษัท ขึ้นอยู่กับบริบทของบริษัทนั้น ๆ\n",
        "\n",
        "เราขอเริ่มอธิบายจากหัวข้อแรก\n",
        "\n",
        "A Maturity\n",
        "Maturity เราอาจจะเรียกได้ว่าเป็นประสบการณ์ของทีม แต่ในที่นี้ขอเรียกว่าความเข้ากันได้ เนื่องจากบางบริษัททีมมีความเข้ากันได้อยู่แล้ว เคยทำงานร่วมกันด้วยความเข้าใจดีเยี่ยม ความเข้ากันได้ของทีมนั้น ๆ ก็จะสูงตาม\n",
        "\n",
        "ในบริบทของ FinOps เราแบ่ง Maturity ออกเป็น 3 ช่วง ได้แก่\n",
        "\n",
        "Crawl\n",
        "ช่วงแรกเริ่มของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง ซึ่งเราสามารถประเมินได้ว่าบริษัทที่อยู่ในช่วงดังกล่าวได้ว่า กระบวนการทำงาน, กระบวนการรายงานผล ยังอยู่ในรูปแบบของ Manual หรือไม่ได้ใช้ระบบอัตโนมัติเข้ามาช่วย รวมถึงการทำงานบางส่วน เช่น Forecast ค่าใช้จ่าย ยังคงต้องคำนวนใหม่ทุกครั้ง ยังไม่ได้สร้างสูตรหรือโมเดลในการช่วยคำนวน ต้องให้ทีม Finance ประเมินทุก ๆ คร้ัง\n",
        "\n",
        "Walk\n",
        "บางบริษัทอาจจะเริ่มจากช่วงนี้เลยก็เป็นไปได้ สำหรับช่วง walk นั้นจะเรียกได้ว่าเป็นช่วงของ Semi-Automate process เนื่องจากทีมมีบุคคลที่มีความสามารถในการสร้าง Automate process ด้วยตัวเอง ไม่ว่าจะเป็นทีม Engineer, ทีม Finance หรือทีม Finance ทำให้งานบางประเภทนั้นมีความสามารถในการทำงานอย่างอัตโนมัติ Automate process ที่สร้างขึ้นมานั้นสามารถให้คนที่ไม่มีความเชี่ยวชาญที่เกี่ยวข้องสามารถใช้งานได้โดยไม่มีผู้เชี่ยวชาญ\n",
        "\n",
        "Run\n",
        "“ทีมที่เพียบพร้อมด้วยสหวิทยาการ” นี่คือคำนิยามแบบเข้าใจง่ายของช่วงนี้ เพราะทีมที่มีความเข้ากันได้สูง สามารถสร้าง Automate process ออกมาได้ตรงประเด็น จำเป็นต้องมีความเข้าใจทั้งในส่วนที่ตัวเองเชี่ยวชาญและความเข้าใจในส่วนที่นอกเหนือจากที่ตัวเองเชี่ยวชาญ เพื่อที่จะสร้างระบบเพื่อส่งมอบข้อมูลเพื่อนำไปใช้ในการตัดสินได้ตลอดเวลา (Realtime) และช่วยให้บุคคลอื่นสามารถตัดสินใจบนข้อมูลได้อย่างทันท่วงที ไม่จำเป็นต้องปรึกษากับทีมอื่น\n",
        "\n",
        "B Principles\n",
        "Principles คือสิ่งที่ระบุถึงสิ่งที่จำเป็นต้องบรรลุเมื่อต้องการนำ FinOps เข้ามาใช้ในบริษัท ส่วนของ Principles นั้นจะมีความใกล้เคียงกับ Framework ที่เกี่ยวข้องกับ Digital transformation อย่างเช่น Agile หรือ DevOps เนื่องจากต้องการให้บริษัทไม่จำเป็นต้องปรับตัวทั้งหมดเพื่อที่จะเริ่มนำ FinOps ไปใช้งาน โดย Principles นั้นมีอยู่ทั้งหมด 6 ข้อได้แก่\n",
        "\n",
        "ทีมต้องทำงานร่วมกัน\n",
        "ทุกคนต้องเป็นเจ้าของการใช้งาน Cloud computing ร่วมกัน\n",
        "FinOps นั้นจะถูกขับเคลื่อนโดยทีมส่วนกลาง\n",
        "Report ที่เกี่ยวข้อง (Engineer, Finance, Business) ต้องเข้าถึงได้และทันท่วงที\n",
        "การตัดสินใจต้องถูกขับเคลื่อนโดยคุณค่าด้านธุรกิจผ่านการใช้งาน Cloud computing\n",
        "ใช้ความได้เปรียบด้าน Variable cost จาก Cloud computing\n",
        "C Personas\n",
        "Personas ในที่นี้จะระบุถึงแรงจูงใจ, ปัญหา, ตัวชี้วัดและสิ่งที่ได้จาก FinOps ซึ่ง Personas นั้นจะถูกแบ่งออกเป็น 5 บุคคลที่เกี่ยวข้องได้แก่\n",
        "\n",
        "1 FinOps Practitioner\n",
        "\n",
        "บุคคลผู้ซึ่งต้องการนำ FinOps เข้ามาใช้กับกระบวนการทำงานปัจจุบันของบริษัท โดยเป็นผู้ที่มีความเข้าใจใน Personas ของผู้อื่นมากที่สุด นิยามอย่างง่ายคือ ทีม Finance มองว่า (Practitioner) เป็นคนจากทีม Engineer แต่ทีม Engineer มองว่าเป็นคนจากทีม Fiannce\n",
        "\n",
        "2 Executive\n",
        "\n",
        "ผู้บริหารคืออีกหนึ่ง Personas ที่ต้องเข้ามามีส่วนเกี่ยวข้องในเงื่อนของการคาดหวังผลลัพธ์และต้องมีส่วนช่วยในการสนับสนุน (Sponsor) การเปลี่ยนแปลงดังกล่าวให้เกิดขึ้นให้ได้\n",
        "\n",
        "3 Business\n",
        "\n",
        "ทีม Business หรือ Product owner ผู้ซึ่งต้องดูแลการเติบโตและวางเป้าหมายให้ตัวผลิตภัฑณ์หรือบริการที่กำลังดูแลอยู่นั้น ส่งมอบมูลค่าแก่ลูกค้าได้อย่างครบถ้วนและตรงจุด เป็นผู้ซึ่งเข้าใจในส่วนของ User หรือ Customer ได้ดีที่สุดจากทั้ง 5 บุคคลที่เกี่ยวข้อง\n",
        "\n",
        "4 Finance\n",
        "\n",
        "ทีม Finance เป็นทีมที่ดูแลเกี่ยวกับการลงทุนในแต่ละโปรเจคและต้องคอยประเมินถึงค่าใช้จ่ายระยะยาว โดยต้องประเมินถึงความคุ้มทุนของโปรเจคที่ต้องลงทุนและประเมินว่าเมื่อถึงเวลาใดจะเป็นจุด Break event point\n",
        "\n",
        "5 Engineer\n",
        "\n",
        "บุคคลที่เป็นคนตัดสินความเป็นไปได้ของการสร้างผลิตภัฑณ์หรือบริการ ซึ่งความเป็นไปได้สำหรับผลิตภัฑณ์หรือบริการทางด้าน software นั้น ตั้งอยู่บนพื้นฐาน 3 สิ่งคือ Quality, Cost และ Time สามารถเลือกได้แค่ 2 ใน 3 เท่านั้น\n",
        "\n",
        "D Phases\n",
        "Phase กล่าวคือวงวนกระบวนการสำหรับ FinOps โดยกระบวนการดังกล่าวนั้นสามารถเริ่มจากกระบวนการใดก็ได้ ไม่จำเป็นต้องเริ่มจาก Inform แต่จำเป็นต้องทำตามลำดับเช่น เริ่มจาก Optimize จากนั้นเรียงไป Operate และ Inform ตามลำดับ ซึ่งเมื่อเราสามารถวนครบรอบได้แล้ว เราสามารถทำต่อไปได้ไม่มีที่สิ้นสุด เนื่องจากทุก ๆ ครั้งในการครบรอบสิ่งที่ทีมจะได้เพิ่มคือความเข้ากันได้ของทีม (Maturity)\n",
        "\n",
        "Phase แบ่งออกด้วยกันทั้งหมด 3 phase ได้แก่\n",
        "\n",
        "1 Inform\n",
        "\n",
        "Phase inform จะเน้นผลลัพธ์ในการสร้างการเข้าถึงข้อมูล, การจัดการข้อมูล, การวัดผล, การกำหนดรายจ่าย และการ forecast รายจ่าย ในส่วนของ Inform จำเป็นต้องสร้างตัวชี้วัดโดยอาศัยข้อมูลจากทีมอื่นเข้ามาเป็นตัวแปรร่วมด้วย\n",
        "\n",
        "2 Optimize\n",
        "\n",
        "หลาย ๆ บริษัทมักอยากจะกระโดดเข้ามาใน Phase นี้เป็นส่วนแรก เนื่องจากเห็นผลได้รวดเร็วและมองเห็นถึงผลลัพธ์ได้ง่าย ในส่วนของ FinOps Foundation นั้นให้ความหมายของ Phase นี้เอาไว้ว่า เป็นช่วงที่ต้องมองหาความเป็นไปได้ในการลดต้นทุนและใช้ทรัพยากรที่มีอยู่ให้มีประสิทธิภาพสูงที่สุด หรือเข้าใจโดยง่ายว่า การ Optimize ทุกอย่างนั้นจะเกิดขึ้นแบบทฤษฎีก่อนนำไปให้ทีมที่เกี่ยวข้องนั้นนำไปใช้งานจริง\n",
        "\n",
        "3 Operate\n",
        "\n",
        "Phase นี้มักเป็นส่วนที่ถูกมองข้ามในการจำกัดความแต่ในการปฏิบัตินั้นเกิดขึ้นโดยไม่รู้ตัว ซึ่งการ Operate จะเป็นการเริ่มติดตามถึงตัวชี้วัดที่เราวางไว้, ติดตามถึงผลกระทบในส่วนของ Quality, Cost และ Time และในส่วนของการลงมือนำแผนการจาก Optimize นำไปใช้จริง\n",
        "\n",
        "E Domain\n",
        "Domain ระบุถึงกลุ่มกิจกรรมที่ให้ผลลัพธ์ออกมาในกลุ่มผลลัพธ์เดียวกัน โดย Domain นั้นจะถูกนำไปใช้ในแต่ Phase โดย Domain นั้นจะถูกกำหนดไว้ ณ ปัจจุบัน 6 Domain ได้แก่\n",
        "\n",
        "1 Understanding cloud usage and cost\n",
        "\n",
        "สำหรับ Domain นี้คือการรวมรวบข้อมูลที่เกี่ยวข้องกับการใช้งาน Cloud computing และนำข้อมูลที่ได้มานั้ดจัดให้อยู่ในรูปแบบที่สามารถเข้าถึงได้ ซึ่งข้อมูลดังกล่าวต้องตอบสนองต่อแต่ละ Personas อย่างครบถ้วน\n",
        "\n",
        "2 Performance Tracking & Benchmarking\n",
        "\n",
        "สำหรับการวัดผลและตั้งเป้าหมายจะถูกกำหนดขึ้น โดยเริ่มจากการตั้งงบประมาณ, การกำหนดผลลัพธ์ที่คาดหวัง หรือ ใช้ข้อมูลย้อนหลังเพื่อเป็นสมมติฐานการคำนวนรายจ่ายในอนาคต การวัดผลและการสร้างตัวชี้วัดทั้งหมดจะถูกสร้างใน Domain นี้\n",
        "\n",
        "3 Real-Time Decision Making\n",
        "\n",
        "การสร้างระบบสำหรับตัดสินใจแบบ Real time จะช่วยให้ผู้ที่มีส่วนได้ส่วนเสียทั้งหมดมีประสิทธิภาพในการรับมือกับสถานการณ์ต่าง ๆ ได้ดียิ่งขึ้น ไม่ว่าจะเป็นในด้านของเวลาในการตัดสินใจ หรือ คุณภาพในการตัดสินใจซึ่งต้องไปในทิศทางเดียวกันกับบริษัท\n",
        "\n",
        "4 Cloud Rate Optimization\n",
        "\n",
        "ภายใน Domain นี้จะกล่าวถึงการทำความเข้าใจเกี่ยวกับรูปแบบการคิดค่าบริการของผู้ให้บริการ Cloud computing และทำการปรับปรุงรายจ่าย Cloud computing ของบริษัทให้สอดคล้องกับรูปแบบการคิดค่าบริการของผู้ให้บริการ โดยคำนึงถึงข้อจำกัดที่แปรผันตามรูปแบบการคิดค่าบริการที่ต่างไป\n",
        "\n",
        "5 Cloud Usage Optimization\n",
        "\n",
        "Domain นี้ให้ความสำคัญถึงการใช้ทรัพยากรที่มีอยู่ให้คุ้มค่าที่สุด โดยการระบุและลงมือเปลี่ยนแปลงงานบางประเภทให้ประมวลผลให้ช่วงเวลาที่ Cloud computing นั้นไม่ได้ใช้งาน และรวมถึงการเปลี่ยนแปลงทรัพยากรที่มีอยู่ในเหมาะสมกับประเภทของงาน\n",
        "\n",
        "6 Organizational Alignment\n",
        "สำหรับ Domain นี้จะกล่าวถึงการที่บริษัทนั้นมีทิศทางในการใช้งาน Cloud computing ในทิศทางเดียวกันผ่าน Principles ของ FinOps ร่วมกัน เพื่อที่จะกำหนดวัฒนธรรมและนโยบายสำหรับบริษัทโดยไม่ขัดแย้งต่อวัฒนธรรมเดิมที่มีอยู่ของบริษัท\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pall4NnPE99r",
        "outputId": "4699e10c-520a-4ce2-e050-b61a181da77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "8dd4f7aa998a400382ccc270a59268b6",
            "a8bf614f7bb5494dbf28c2d4e6df358d",
            "18a3c33192244cf3b57fc6727ae342d1",
            "bc401d29b43e409a9d7852a497c7386d",
            "3b8d49cb9ee04f2d81865644a4ff4be9",
            "9429e892d8f24f79a93babb0d84f2c3c",
            "9778af3baa724840ba54ad659a8dc04d",
            "cc7c1033ddb749f28ee9e72156d31504",
            "668a14539c36465187cdb0353926526a",
            "dead8c7ac7f64dfc8650acff918abb6d",
            "033d0a9f727544b1a543662176c40233",
            "5382bc139f82478aafe11ac8665348c7",
            "e559b5688b574f538f40f1f28a0ee49c",
            "e2b27a96df54478d8d39a6a2b255dfed",
            "d2b45bd094ec48f5b5fa38403016518b",
            "fdf55aaf62884b18a11b6614a2c3ff14",
            "cb1979a937c040bdbbd8c477359c2eca",
            "809722233d234402a41f1c93e767b1ec",
            "9a17799034544cb0939a3c87e6600ef8",
            "4b9a08a679fa455c962b689b2963e984",
            "a127f67bd108480cb8bf4f4f07bce943",
            "6480c7972e314f9e8333943567c7cb69",
            "a0253a6e90ef4b758f9fe13f8d65e7ce",
            "5c21cd5cc45a418688bea102c7347d95",
            "5163bbcb79944b36b12ceed50455c9fe",
            "0b524fd71da44180bd433ed314bb56ce",
            "08668df771bc46b088fe34863df16d23",
            "aff0d510ef494db7aead5bcc35f01167",
            "54153b7bb3f94906b77d259440898243",
            "30fcba22562f42c2b1b4d59f86290111",
            "76f8199eb1d0437d9c32a78c7b7d0604",
            "2565453171c84abe9c030f8599fd31ee",
            "f64e2ee94d634f128cdd29583e1a42b5",
            "44ae49ccd4344e72ab62b38c0f5c31cc",
            "83243e18d2144458ae2a813a91b2b593",
            "c389921042844af58430a79d53b4bdb8",
            "22c76a03fd3e48ca86e511a3fcb0e91f",
            "c714206caa0c4be3b0b1a34194c4fbc3",
            "7731e095284c4a539ed4bbb9f6335f4d",
            "92b98cc497064128b06d408e405f7285",
            "23568a724c3a419d9611337d3ed1f14a",
            "b7a5dea284324bbdb377ef6634cd596c",
            "34918ebb4aaf4e13aba54ddb718c1693",
            "8299e6b01a5c4909ad0136e0f9bf7c7b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dd4f7aa998a400382ccc270a59268b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/780k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5382bc139f82478aafe11ac8665348c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0253a6e90ef4b758f9fe13f8d65e7ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44ae49ccd4344e72ab62b38c0f5c31cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from pythainlp.tokenize import sent_tokenize\n",
        "import tiktoken\n",
        "from transformers import AutoTokenizer\n",
        "from typing import Callable, List\n",
        "\n",
        "def thai_sent_tokenize() -> Callable[[str], List[str]]:\n",
        "    def split(text: str) -> List[str]:\n",
        "        return sent_tokenize(text)\n",
        "    return split\n",
        "\n",
        "spliter = SentenceSplitter(\n",
        "    separator=\" \",\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=256,\n",
        "    paragraph_separator='\\n',\n",
        "    # tokenizer=tiktoken.encoding_for_model('gpt-3.5-turbo').encode,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"SeaLLMs/SeaLLM-7B-v2\").encode,\n",
        "    # chunking_tokenizer_fn=thai_sent_tokenize(),\n",
        "    include_metadata=True,\n",
        "    include_prev_next_rel=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtOHr4ErE99s",
        "outputId": "e9d58af4-9943-4473-e65f-e3d0915aedb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12672 5\n",
            "II FinOps ?\n",
            "A FinOps (cloud Financial Operations)\n",
            "FinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\n",
            "\n",
            "B History\n",
            "FinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\n",
            "III Cloud in real life\n",
            "การใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\n",
            "A Spending decision\n",
            "ความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud environment เรียบร้อยแล้ว คนที่เข้าใจ Cloud มากที่สุดกลับเป็นทีม Engineer ที่ไม่มีหน้าที่ในการรับผิดชอบการใช้จ่ายของบริษัท หรือเมื่อ Spending decision ยังอยู่กับทีม Financial คนที่ต้อง Commit รายจ่ายของ Cloud computing ก็ยังคงเป็นทีม Engineer\n",
            "\n",
            "ถ้าไม่แก้ไขปัญหาจากเหตุการณ์ดังกล่าวจะเกิดเหตุการณ์ Engineer Commit รายจ่ายให้สูงเกินความจำเป็น หรือ การใช้งานบางอย่าง (Serverless) ส่งผลให้เกิดรายจ่ายที่ผิดปกติในเดือนนั้น ๆ โดยไม่ทราบสาเหตุ\n",
            "\n",
            "วิธีแก้ไขของหลายบริษัทคือการให้ Engineer ลดรายจ่ายให้อยู่ในเพดานที่เหมาะสม\n",
            "\n",
            "อ่านดูแล้วอาจเป็นวิธีการแก้ปัญหาที่ตรงจุด แต่วิธีดังกล่าวกลับเหมาะสมกับบริบทดั้งเดิม ไม่สมเหตุสมผลกับบริบทปัจจุบัน เพราะการกระจายอำนาจตัดสินใจให้กับทีมอื่นได้นั้นถือเป็นความสามารถที่ไม่เคยเกิดขึ้นมาก่อนและยังสอดคล้องกับการทำงานยุคใหม่ที่ใช้ Framework อย่างเช่น Agile ที่ต้องการให้เกิดความรวดเร็วในการตัดสินใจ\n",
            "\n",
            "B Variable spending\n",
            "การใช้งานบางบริษัทของผู้ให้บริการ Cloud computing ไม่ได้คิดค่าบริการตามจำนวนชั่วโมงที่ใช้งานอย่างที่เราเข้าใจ แต่การคิดค่าบริการอาจคิดจากจำนวนการเรียกใช้งานหรือจำนวนของ bandwidth เป็นต้น\n",
            "\n",
            "ลักษณะการคิดค่าบริการดังกล่าวมีข้อดีคือเป็นการคิดค่าใช้จ่ายแบบ Variable cost เราสามารถนำไปใช้ในการคำนวณหา Cost Of Goods Sold (COGS) ได้ทันที\n",
            "\n",
            "ส่วนข้อเสียคือถ้าทีม Financial ไม่เข้าใจที่มาของต้นทุนดังกล่าวแล้วไม่ได้ลงไว้ใน Variable cost หรือ COGS จะเกิดคำถามว่าทำไมค่าใช้จ่าย Cloud computing ในแต่ละเดือนนั้น ไม่เท่ากันและไม่สามารถพิจารณาค่าใช้จ่าย Cloud computing ล่วงหน้า\n",
            "\n",
            "วิธีแก้ไขของหลายบริษัทคือไม่ใช้งาน Cloud computing ในส่วน Variable cost หรือไม่ต้องใช้งาน Cloud ไปเลย\n",
            "\n",
            "C Scalable resource\n",
            "การปรับจำนวนทรัพยากรได้ตลอดเวลานั้นสามารถส่งเสริมให้เกิดนวัตกรรมได้ตลอดเวลา เนื่องจากทีม Engineer สามารถเข้าถึงทรัพยากรได้อย่างรวดเร็วและเข้าถึงบางทรัพยากรที่ไม่เคยมีมาก่อน เช่น การเข้าถึง High performance computer, การเข้าถึง Computer cluster เป็นต้น สิ่งเหล่านี้จะทำให้ทีม Engineer สามารถทดลองนวัตกรรมใหม่ ๆ หรือสำรวจความเป็นไปได้ใหม่ ๆ โดยปราศจากข้อจำกัดด้านการจัดซื้อ\n",
            "---\n",
            "ส่วนข้อเสียคือถ้าทีม Financial ไม่เข้าใจที่มาของต้นทุนดังกล่าวแล้วไม่ได้ลงไว้ใน Variable cost หรือ COGS จะเกิดคำถามว่าทำไมค่าใช้จ่าย Cloud computing ในแต่ละเดือนนั้น ไม่เท่ากันและไม่สามารถพิจารณาค่าใช้จ่าย Cloud computing ล่วงหน้า\n",
            "\n",
            "วิธีแก้ไขของหลายบริษัทคือไม่ใช้งาน Cloud computing ในส่วน Variable cost หรือไม่ต้องใช้งาน Cloud ไปเลย\n",
            "\n",
            "C Scalable resource\n",
            "การปรับจำนวนทรัพยากรได้ตลอดเวลานั้นสามารถส่งเสริมให้เกิดนวัตกรรมได้ตลอดเวลา เนื่องจากทีม Engineer สามารถเข้าถึงทรัพยากรได้อย่างรวดเร็วและเข้าถึงบางทรัพยากรที่ไม่เคยมีมาก่อน เช่น การเข้าถึง High performance computer, การเข้าถึง Computer cluster เป็นต้น สิ่งเหล่านี้จะทำให้ทีม Engineer สามารถทดลองนวัตกรรมใหม่ ๆ หรือสำรวจความเป็นไปได้ใหม่ ๆ โดยปราศจากข้อจำกัดด้านการจัดซื้อ\n",
            "\n",
            "แต่ข้อเสียที่เกิดขึ้นเมื่อทีม Engineer สามารถเข้าถึงทรัพยากรเหล่านี้ได้โดยปราศจากการอนุมัติจากทีม Finance บางครั้งทีม Engineer อาจจะลืมหรือละเลยการใช้งานทรัพยากรเหล่านี้โดยเปิดทิ้งไว้ตลอดเวลา แต่ใช้งานจริงแค่เพียง 1% ของเวลาที่คิดค่าใช้จ่าย  ทำให้เกิดค่าใช้จ่ายส่วนเกินที่ไม่ควรเกิดขึ้น\n",
            "\n",
            "ดังนั้นเพื่อเป็นการป้องกันปัญหาดังกล่าวจำเป็นต้องให้เกิดการตรวจสอบการใช้งานได้ตลอดเวลา เพื่อติดตามและป้องกันไม่ให้เกิดปัญหาดังกล่าว\n",
            "\n",
            "VII  FinOps framework ถูกสร้างขึ้นมาโดยมีหัวข้อหลักทั้งหมด 5 หัวข้อ ดังนี้\n",
            "Maturity\n",
            "Principles\n",
            "Personas\n",
            "Phases\n",
            "Domains\n",
            "โดยแต่ละหัวข้อจะอธิบายถึงสถานะ, เครื่องมือ, กิจกรรม, ความเข้ากันได้ หรือ สิ่งขับเคลื่อน ซึ่งแต่ละหัวข้อสามารถแยกพิจารณาเมื่อไหร่ก็ได้ ไม่จำเป็นต้องเรียงลำดับและในแต่ละบริษัทไม่จำที่จะต้องให้น้ำหนักกับแต่ละหัวข้อเหมือนกันทุกบริษัท ขึ้นอยู่กับบริบทของบริษัทนั้น ๆ\n",
            "\n",
            "เราขอเริ่มอธิบายจากหัวข้อแรก\n",
            "\n",
            "A Maturity\n",
            "Maturity เราอาจจะเรียกได้ว่าเป็นประสบการณ์ของทีม แต่ในที่นี้ขอเรียกว่าความเข้ากันได้ เนื่องจากบางบริษัททีมมีความเข้ากันได้อยู่แล้ว เคยทำงานร่วมกันด้วยความเข้าใจดีเยี่ยม ความเข้ากันได้ของทีมนั้น ๆ ก็จะสูงตาม\n",
            "\n",
            "ในบริบทของ FinOps เราแบ่ง Maturity ออกเป็น 3 ช่วง ได้แก่\n",
            "\n",
            "Crawl\n",
            "ช่วงแรกเริ่มของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง ซึ่งเราสามารถประเมินได้ว่าบริษัทที่อยู่ในช่วงดังกล่าวได้ว่า กระบวนการทำงาน, กระบวนการรายงานผล ยังอยู่ในรูปแบบของ Manual หรือไม่ได้ใช้ระบบอัตโนมัติเข้ามาช่วย รวมถึงการทำงานบางส่วน เช่น Forecast ค่าใช้จ่าย ยังคงต้องคำนวนใหม่ทุกครั้ง ยังไม่ได้สร้างสูตรหรือโมเดลในการช่วยคำนวน ต้องให้ทีม Finance ประเมินทุก ๆ คร้ัง\n",
            "\n",
            "Walk\n",
            "บางบริษัทอาจจะเริ่มจากช่วงนี้เลยก็เป็นไปได้ สำหรับช่วง walk นั้นจะเรียกได้ว่าเป็นช่วงของ Semi-Automate process เนื่องจากทีมมีบุคคลที่มีความสามารถในการสร้าง Automate process ด้วยตัวเอง ไม่ว่าจะเป็นทีม Engineer, ทีม Finance หรือทีม Finance ทำให้งานบางประเภทนั้นมีความสามารถในการทำงานอย่างอัตโนมัติ Automate process ที่สร้างขึ้นมานั้นสามารถให้คนที่ไม่มีความเชี่ยวชาญที่เกี่ยวข้องสามารถใช้งานได้โดยไม่มีผู้เชี่ยวชาญ\n",
            "\n",
            "Run\n"
          ]
        }
      ],
      "source": [
        "nodes = spliter.split_text(text)\n",
        "total = 0\n",
        "for i in nodes :\n",
        "    total += len(i)\n",
        "print(total,len(nodes))\n",
        "print(nodes[0])\n",
        "print('---')\n",
        "print(nodes[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IM2m9rmE99t",
        "outputId": "f86fd209-4e01-48ff-c1c2-2dbaac120bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13237 23\n",
            "II FinOps ?\n",
            "A FinOps (cloud Financial Operations)\n",
            "FinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\n",
            "\n",
            "B History\n",
            "FinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case\n",
            "---\n",
            "2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\n",
            "III Cloud in real life\n",
            "การใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\n",
            "A Spending decision\n",
            "ความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from pythainlp.tokenize import sent_tokenize\n",
        "import tiktoken\n",
        "from transformers import AutoTokenizer\n",
        "from typing import Callable, List\n",
        "\n",
        "token_spliter = TokenTextSplitter(\n",
        "    # tokenizer=tiktoken.encoding_for_model('gpt-3.5-turbo').encode,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"SeaLLMs/SeaLLM-7B-v2\").encode,\n",
        "    separator=\" \",\n",
        "    chunk_size=256,\n",
        "    chunk_overlap=64,\n",
        "    include_metadata=True,\n",
        "    include_prev_next_rel=True,\n",
        ")\n",
        "\n",
        "nodes = token_spliter.split_text(text)\n",
        "total = 0\n",
        "for i in nodes :\n",
        "    total += len(i)\n",
        "print(total,len(nodes))\n",
        "print(nodes[0])\n",
        "print('---')\n",
        "print(nodes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkruJPbQFI44"
      },
      "source": [
        "# Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKUo3i6IFI45",
        "outputId": "cba6d4a3-0509-44ec-e813-17ecc15e8416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "e3b85b19af16463bb0ebc3aefe3274b9",
            "e222a6d4ae674213adcbd949675a2918",
            "e19ef9357a3a4790a944b225ee7be804",
            "0ec153c366434a1fb489ae56ac020429",
            "95c0f7981aa64723a9378cf013ff40db",
            "6733fb49af9b4df287333bb5a215db10",
            "bb6185e0bcb545a3a860b55ce9c058dd",
            "e693d094b0c94034b8ae312b9131d93d",
            "a5365edf9b984ae0b159821909f65ea2",
            "f77234ac1a2c4b1eac82f5dfb3ed9da2",
            "5e823a5929694d24a200e45ee9fe1549",
            "e4ed0bd42e6c4237aa554ff891e8a3eb",
            "acff5ccd7ede4e0dac9d8991a98124c7",
            "67e1944b56f94243a81854d7fb70ff1b",
            "bf195af1747b4e1eb557cc9a2092fac7",
            "b849c09ba563408db41c70debed13108",
            "363f0e1095ae42d1a4b659e9d7a08f7c",
            "db8ca3bc4f284a749fb6790d5c0fd620",
            "91284415f258459896810c076c225a00",
            "05ca068f365149c58d02b49f70c3b856",
            "52e6430d264346469a48a2b78b2d392e",
            "ab8b5575d4724e7d8583c735cc8693e6",
            "6414efe767ff46bba640fa2733881769",
            "89e02f6dee2d4ad9aa900c49419fcea1",
            "831f9ed054334a6ebcaa687ce466ad3a",
            "040396640a7a435292c439b1d483eef5",
            "e20d7ef7da21425a80a70e35536879b4",
            "014ee68ffb5f46d6afe080041589adea",
            "4397e90b5328499da28c3cb933b2125b",
            "05df7a57d60d4a1697105c0c01d093ea",
            "9ed5d926bb18466dae2f3d245e3fae5b",
            "4df79ff379eb481c822a5a3e82a1bfa5",
            "fe8562edf8d64222b3d0f231b52a74c2",
            "c290bc2da7ac46dc9801f0a817a3410e",
            "e678e36f4bdb4977a2e49bc55a52c346",
            "20cadb3527fb41f0aa45931ce8ef608e",
            "d616011a7ad442f1af807ca39620c4e2",
            "ce62e9da75794f12be7e40ba08043645",
            "950b9c86cc3841df9081061b91d14eb4",
            "4d47bd75aa944ead91624d7da230a42b",
            "d70a1a9c114e4893bed52ba0f769681a",
            "adbb45b87c084fb092dccc14f26c192d",
            "431939de8d1245f6a757a5b6b69d0bf8",
            "530e88a8eae04922b1f0882afd982733",
            "680082e54ca3455f8fe06a5d476868c7",
            "a29fdf4b6c9d404980b02fc874a01c15",
            "069420731e6a423ca2b369b5b7551659",
            "82b8b358f5ac4780b33008d0d90a603d",
            "d551f324c95f40d4b04c9275224492c9",
            "b035c36868374f8097dada270cf94b46",
            "d1ae6482b93943e7b224edcc0e3cb464",
            "7c9eb7377d774aaab6af84cda5b2ed7e",
            "daf52fb3f5b149c6b21b03ba77d8a05e",
            "520c6691aa954859bb425cac7512d703",
            "d5b874275858455f9e2f3d277765ccbe",
            "e92f06601e1648378a9c54fce50a1545",
            "8093db9b41d1444a8710475bc40263fd",
            "cd540d5b69e647d08d1854fed30dafba",
            "8835a727579e404e97d85a40430fb71c",
            "740ee01875a54392b70180d3eaa8b9c9",
            "f1606eeb25b147fcbf6bd1543fcec61b",
            "68d5968b5e134406bbd0e6dbe205768a",
            "44030f4e93aa48fb9e1296b4cdc135be",
            "7ba23484279b4bef860bf9d84f071092",
            "b14c791dae704aa1ba2baa7f9a2723e5",
            "e3d626f9f7d94cdb9a69b53ef3de39fd"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b85b19af16463bb0ebc3aefe3274b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4ed0bd42e6c4237aa554ff891e8a3eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6414efe767ff46bba640fa2733881769"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c290bc2da7ac46dc9801f0a817a3410e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "680082e54ca3455f8fe06a5d476868c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e92f06601e1648378a9c54fce50a1545"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.readers.file import FlatReader\n",
        "from pathlib import Path\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")\n",
        "documents = FlatReader().load_data(Path(\"./MockupData/data.md\"))\n",
        "index = VectorStoreIndex.from_documents(documents,embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(index)"
      ],
      "metadata": {
        "id": "76fZywE2dc8V",
        "outputId": "497c1267-6be0-4f38-a5a3-3e661116265f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x7b9f53f77f40>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyURAzD5FNXr"
      },
      "source": [
        "# Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in memory"
      ],
      "metadata": {
        "id": "HBvuX4ty9k-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from pathlib import Path\n",
        "\n",
        "sentence_spilit = SentenceSplitter(\n",
        "    chunk_size=1024\n",
        ")\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "md_docs = FlatReader().load_data(Path(\"./MockupData/finops.md\"))\n",
        "md_nodes = sentence_spilit.get_nodes_from_documents(md_docs)\n",
        "\n",
        "print(len(md_nodes))\n",
        "index = VectorStoreIndex(md_nodes,embed_model=embed_model)\n",
        "# Query index\n",
        "query_engine = index.as_retriever(similarity_top_k = 5)\n",
        "response = query_engine.retrieve(\"FinOps คืออะไร?\")\n",
        "print('-------------RAG-------------')\n",
        "print(len(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SncGxTHB-0Kc",
        "outputId": "4d224825-7bea-4f7d-b6e4-68dd18d6d3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "-------------RAG-------------\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "separate 2 end point in storage context\n",
        "download from storage to reduce compute time"
      ],
      "metadata": {
        "id": "nE3rIg-P-nx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.vector_stores import SimpleVectorStore\n",
        "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
        "from llama_index.core.storage.index_store import SimpleIndexStore\n",
        "from llama_index.core import VectorStoreIndex,StorageContext\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from pathlib import Path\n",
        "\n",
        "sentence_spilit = SentenceSplitter(\n",
        "    chunk_size=1024\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=SimpleVectorStore(),\n",
        "    docstore=SimpleDocumentStore(),\n",
        "    index_store=SimpleIndexStore(),\n",
        ")\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "md_docs = FlatReader().load_data(Path(\"./MockupData/finops.md\"))\n",
        "md_nodes = sentence_spilit.get_nodes_from_documents(md_docs)\n",
        "\n",
        "print(len(md_nodes))\n",
        "index = VectorStoreIndex(md_nodes,embed_model=embed_model,storage_context=storage_context)\n",
        "index.set_index_id(\"FinOps\")\n",
        "index.storage_context.persist(persist_dir=\"./localstore/\")\n",
        "# Query index\n",
        "query_engine = index.as_retriever(similarity_top_k = 5)\n",
        "response = query_engine.retrieve(\"FinOps คืออะไร?\")\n",
        "print('-------------RAG-------------')\n",
        "print(len(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d224825-7bea-4f7d-b6e4-68dd18d6d3b9",
        "id": "rhUuCaHq_Oqb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "-------------RAG-------------\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeyWKwEvFQ9W"
      },
      "source": [
        "# Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCbiOxUqFQ9Y"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext,load_index_from_storage\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "\n",
        "load_index = load_index_from_storage(StorageContext.from_defaults(persist_dir='./localstore/'),embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrival**  \n",
        "no data send to LLM  \n",
        "debug before sending"
      ],
      "metadata": {
        "id": "_fMCBesvKaCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxCFEE_oFQ9a",
        "outputId": "ad6c0a72-ddb4-4449-e336-f0ead589d163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------RAG-------------\n",
            "[NodeWithScore(node=TextNode(id_='f6f1d2f7-b70f-4ce8-afd4-82594f15764e', embedding=None, metadata={'filename': 'finops.md', 'extension': '.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29c14040-3d75-4e8c-b397-7181757629b8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='d5fbef9aa2cb4c27540f17fbc495a4e8c0c3b06af253f70394eeeb3e34a07ba9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0bbd28f9-ba8e-4887-bed1-8473640ade3c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c18455576ae9bbffa7d79e1009f948ab3675f4f62afec647200656774c91f0b0')}, text='II FinOps ?  \\nA FinOps (cloud Financial Operations)\\nFinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\\n\\nB History\\nFinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\\nIII Cloud in real life  \\nการใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\\nA Spending decision\\nความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud environment เรียบร้อยแล้ว คนที่เข้าใจ Cloud มากที่สุดกลับเป็นทีม Engineer ที่ไม่มีหน้าที่ในการรับผิดชอบการใช้จ่ายของบริษัท หรือเมื่อ Spending decision ยังอยู่กับทีม Financial คนที่ต้อง Commit รายจ่ายของ Cloud computing ก็ยังคงเป็นทีม Engineer\\n\\nถ้าไม่แก้ไขปัญหาจากเหตุการณ์ดังกล่าวจะเกิดเหตุการณ์ Engineer Commit รายจ่ายให้สูงเกินความจำเป็น หรือ การใช้งานบางอย่าง (Serverless) ส่งผลให้เกิดรายจ่ายที่ผิดปกติในเดือนนั้น ๆ', start_char_idx=0, end_char_idx=1475, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8873275897977735), NodeWithScore(node=TextNode(id_='b9ba1b0e-796a-4fa9-9748-a9c96b72e0ff', embedding=None, metadata={'filename': 'finops.md', 'extension': '.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29c14040-3d75-4e8c-b397-7181757629b8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='d5fbef9aa2cb4c27540f17fbc495a4e8c0c3b06af253f70394eeeb3e34a07ba9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14f6f62c-7a1e-4a0d-9b56-60860a075bb2', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='719ab3b601ff28c29fc862220bab014fdc7fa58a647f4d57293bb9896977f8e4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='19da5c96-aaa5-4662-a534-2c8547c2c596', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcd76116e48db75b50b75a791c1a04589bacc7035a8d07d150da79ef0fa45548')}, text='Cost และ Time สามารถเลือกได้แค่ 2 ใน 3 เท่านั้น\\n\\nD Phases\\nPhase กล่าวคือวงวนกระบวนการสำหรับ FinOps โดยกระบวนการดังกล่าวนั้นสามารถเริ่มจากกระบวนการใดก็ได้ ไม่จำเป็นต้องเริ่มจาก Inform แต่จำเป็นต้องทำตามลำดับเช่น เริ่มจาก Optimize จากนั้นเรียงไป Operate และ Inform ตามลำดับ ซึ่งเมื่อเราสามารถวนครบรอบได้แล้ว เราสามารถทำต่อไปได้ไม่มีที่สิ้นสุด เนื่องจากทุก ๆ ครั้งในการครบรอบสิ่งที่ทีมจะได้เพิ่มคือความเข้ากันได้ของทีม (Maturity)\\n\\nPhase แบ่งออกด้วยกันทั้งหมด 3 phase ได้แก่\\n\\n1 Inform\\n\\nPhase inform จะเน้นผลลัพธ์ในการสร้างการเข้าถึงข้อมูล, การจัดการข้อมูล, การวัดผล, การกำหนดรายจ่าย และการ forecast รายจ่าย ในส่วนของ Inform จำเป็นต้องสร้างตัวชี้วัดโดยอาศัยข้อมูลจากทีมอื่นเข้ามาเป็นตัวแปรร่วมด้วย\\n\\n2 Optimize\\n\\nหลาย ๆ บริษัทมักอยากจะกระโดดเข้ามาใน Phase นี้เป็นส่วนแรก เนื่องจากเห็นผลได้รวดเร็วและมองเห็นถึงผลลัพธ์ได้ง่าย ในส่วนของ FinOps Foundation นั้นให้ความหมายของ Phase นี้เอาไว้ว่า เป็นช่วงที่ต้องมองหาความเป็นไปได้ในการลดต้นทุนและใช้ทรัพยากรที่มีอยู่ให้มีประสิทธิภาพสูงที่สุด หรือเข้าใจโดยง่ายว่า การ Optimize ทุกอย่างนั้นจะเกิดขึ้นแบบทฤษฎีก่อนนำไปให้ทีมที่เกี่ยวข้องนั้นนำไปใช้งานจริง\\n\\n3 Operate\\n\\nPhase นี้มักเป็นส่วนที่ถูกมองข้ามในการจำกัดความแต่ในการปฏิบัตินั้นเกิดขึ้นโดยไม่รู้ตัว ซึ่งการ Operate จะเป็นการเริ่มติดตามถึงตัวชี้วัดที่เราวางไว้,', start_char_idx=7231, end_char_idx=8479, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8751036805770269), NodeWithScore(node=TextNode(id_='14f6f62c-7a1e-4a0d-9b56-60860a075bb2', embedding=None, metadata={'filename': 'finops.md', 'extension': '.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29c14040-3d75-4e8c-b397-7181757629b8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='d5fbef9aa2cb4c27540f17fbc495a4e8c0c3b06af253f70394eeeb3e34a07ba9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6cb92c6-3e1f-495e-8446-36b308d85ea2', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='241ebfa60f2cf54a22c9a294673d3a501af3304c56cbd787135372c1c7e3f2a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9ba1b0e-796a-4fa9-9748-a9c96b72e0ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25a2b7021957a276d487f68559c332b452b42464942ae92be957f590d7d26128')}, text='Finance, Business) ต้องเข้าถึงได้และทันท่วงที\\nการตัดสินใจต้องถูกขับเคลื่อนโดยคุณค่าด้านธุรกิจผ่านการใช้งาน Cloud computing\\nใช้ความได้เปรียบด้าน Variable cost จาก Cloud computing\\nC Personas\\nPersonas ในที่นี้จะระบุถึงแรงจูงใจ, ปัญหา, ตัวชี้วัดและสิ่งที่ได้จาก FinOps ซึ่ง Personas นั้นจะถูกแบ่งออกเป็น 5 บุคคลที่เกี่ยวข้องได้แก่\\n\\n1 FinOps Practitioner\\n\\nบุคคลผู้ซึ่งต้องการนำ FinOps เข้ามาใช้กับกระบวนการทำงานปัจจุบันของบริษัท โดยเป็นผู้ที่มีความเข้าใจใน Personas ของผู้อื่นมากที่สุด นิยามอย่างง่ายคือ ทีม Finance มองว่า (Practitioner) เป็นคนจากทีม Engineer แต่ทีม Engineer มองว่าเป็นคนจากทีม Fiannce\\n\\n2 Executive\\n\\nผู้บริหารคืออีกหนึ่ง Personas ที่ต้องเข้ามามีส่วนเกี่ยวข้องในเงื่อนของการคาดหวังผลลัพธ์และต้องมีส่วนช่วยในการสนับสนุน (Sponsor) การเปลี่ยนแปลงดังกล่าวให้เกิดขึ้นให้ได้  \\n\\n3 Business\\n\\nทีม Business หรือ Product owner ผู้ซึ่งต้องดูแลการเติบโตและวางเป้าหมายให้ตัวผลิตภัฑณ์หรือบริการที่กำลังดูแลอยู่นั้น ส่งมอบมูลค่าแก่ลูกค้าได้อย่างครบถ้วนและตรงจุด เป็นผู้ซึ่งเข้าใจในส่วนของ User หรือ Customer ได้ดีที่สุดจากทั้ง 5 บุคคลที่เกี่ยวข้อง\\n\\n4 Finance\\n\\nทีม Finance เป็นทีมที่ดูแลเกี่ยวกับการลงทุนในแต่ละโปรเจคและต้องคอยประเมินถึงค่าใช้จ่ายระยะยาว โดยต้องประเมินถึงความคุ้มทุนของโปรเจคที่ต้องลงทุนและประเมินว่าเมื่อถึงเวลาใดจะเป็นจุด Break event point\\n\\n5 Engineer\\n\\nบุคคลที่เป็นคนตัดสินความเป็นไปได้ของการสร้างผลิตภัฑณ์หรือบริการ ซึ่งความเป็นไปได้สำหรับผลิตภัฑณ์หรือบริการทางด้าน software นั้น ตั้งอยู่บนพื้นฐาน 3 สิ่งคือ Quality,', start_char_idx=5800, end_char_idx=7230, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8740387428434587), NodeWithScore(node=TextNode(id_='d7ad2e52-610f-46f5-a394-b17039f4eeaf', embedding=None, metadata={'filename': 'finops.md', 'extension': '.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29c14040-3d75-4e8c-b397-7181757629b8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='d5fbef9aa2cb4c27540f17fbc495a4e8c0c3b06af253f70394eeeb3e34a07ba9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0b767413-6bdc-492a-b79b-daaabcfb4c25', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='e9e85323e12ec6f307464fe751deb009f023b3ad202ecb6d8ca4e940d5a4582c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec8160a0-a4b8-4e9b-9a30-e2d3638b271d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32cc6925577af327b849a69022a0a4d1bc68a41a423c141a75b08002a9a98a3c')}, text='เครื่องมือ, กิจกรรม, ความเข้ากันได้ หรือ สิ่งขับเคลื่อน ซึ่งแต่ละหัวข้อสามารถแยกพิจารณาเมื่อไหร่ก็ได้ ไม่จำเป็นต้องเรียงลำดับและในแต่ละบริษัทไม่จำที่จะต้องให้น้ำหนักกับแต่ละหัวข้อเหมือนกันทุกบริษัท ขึ้นอยู่กับบริบทของบริษัทนั้น ๆ\\n\\nเราขอเริ่มอธิบายจากหัวข้อแรก\\n\\nA Maturity\\nMaturity เราอาจจะเรียกได้ว่าเป็นประสบการณ์ของทีม แต่ในที่นี้ขอเรียกว่าความเข้ากันได้ เนื่องจากบางบริษัททีมมีความเข้ากันได้อยู่แล้ว เคยทำงานร่วมกันด้วยความเข้าใจดีเยี่ยม ความเข้ากันได้ของทีมนั้น ๆ ก็จะสูงตาม\\n\\nในบริบทของ FinOps เราแบ่ง Maturity ออกเป็น 3 ช่วง ได้แก่\\n\\nCrawl\\nช่วงแรกเริ่มของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง ซึ่งเราสามารถประเมินได้ว่าบริษัทที่อยู่ในช่วงดังกล่าวได้ว่า กระบวนการทำงาน, กระบวนการรายงานผล ยังอยู่ในรูปแบบของ Manual หรือไม่ได้ใช้ระบบอัตโนมัติเข้ามาช่วย รวมถึงการทำงานบางส่วน เช่น Forecast ค่าใช้จ่าย ยังคงต้องคำนวนใหม่ทุกครั้ง ยังไม่ได้สร้างสูตรหรือโมเดลในการช่วยคำนวน ต้องให้ทีม Finance ประเมินทุก ๆ คร้ัง\\n\\nWalk\\nบางบริษัทอาจจะเริ่มจากช่วงนี้เลยก็เป็นไปได้ สำหรับช่วง walk นั้นจะเรียกได้ว่าเป็นช่วงของ Semi-Automate process เนื่องจากทีมมีบุคคลที่มีความสามารถในการสร้าง Automate process ด้วยตัวเอง ไม่ว่าจะเป็นทีม Engineer,', start_char_idx=3530, end_char_idx=4665, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8734551689692094), NodeWithScore(node=TextNode(id_='c2402a3f-8054-4212-9889-a879e8d1ea07', embedding=None, metadata={'filename': 'finops.md', 'extension': '.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29c14040-3d75-4e8c-b397-7181757629b8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='d5fbef9aa2cb4c27540f17fbc495a4e8c0c3b06af253f70394eeeb3e34a07ba9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19da5c96-aaa5-4662-a534-2c8547c2c596', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'finops.md', 'extension': '.md'}, hash='ec223405c5bdea783c79cec5e1c0f78ab276c9aaaf6af4525c1bbdd2f3b3dacb')}, text='การกำหนดผลลัพธ์ที่คาดหวัง หรือ ใช้ข้อมูลย้อนหลังเพื่อเป็นสมมติฐานการคำนวนรายจ่ายในอนาคต การวัดผลและการสร้างตัวชี้วัดทั้งหมดจะถูกสร้างใน Domain นี้\\n\\n3 Real-Time Decision Making\\n\\nการสร้างระบบสำหรับตัดสินใจแบบ Real time จะช่วยให้ผู้ที่มีส่วนได้ส่วนเสียทั้งหมดมีประสิทธิภาพในการรับมือกับสถานการณ์ต่าง ๆ ได้ดียิ่งขึ้น ไม่ว่าจะเป็นในด้านของเวลาในการตัดสินใจ หรือ คุณภาพในการตัดสินใจซึ่งต้องไปในทิศทางเดียวกันกับบริษัท\\n\\n4 Cloud Rate Optimization\\n\\nภายใน Domain นี้จะกล่าวถึงการทำความเข้าใจเกี่ยวกับรูปแบบการคิดค่าบริการของผู้ให้บริการ Cloud computing และทำการปรับปรุงรายจ่าย Cloud computing ของบริษัทให้สอดคล้องกับรูปแบบการคิดค่าบริการของผู้ให้บริการ โดยคำนึงถึงข้อจำกัดที่แปรผันตามรูปแบบการคิดค่าบริการที่ต่างไป\\n\\n5 Cloud Usage Optimization\\n\\nDomain นี้ให้ความสำคัญถึงการใช้ทรัพยากรที่มีอยู่ให้คุ้มค่าที่สุด โดยการระบุและลงมือเปลี่ยนแปลงงานบางประเภทให้ประมวลผลให้ช่วงเวลาที่ Cloud computing นั้นไม่ได้ใช้งาน และรวมถึงการเปลี่ยนแปลงทรัพยากรที่มีอยู่ในเหมาะสมกับประเภทของงาน\\n\\n6 Organizational Alignment\\nสำหรับ Domain นี้จะกล่าวถึงการที่บริษัทนั้นมีทิศทางในการใช้งาน Cloud computing ในทิศทางเดียวกันผ่าน Principles ของ FinOps ร่วมกัน เพื่อที่จะกำหนดวัฒนธรรมและนโยบายสำหรับบริษัทโดยไม่ขัดแย้งต่อวัฒนธรรมเดิมที่มีอยู่ของบริษัท', start_char_idx=9103, end_char_idx=10315, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8704583180047608)]\n"
          ]
        }
      ],
      "source": [
        "retrieval_engine = load_index.as_retriever(similarity_top_k = 5)\n",
        "response = retrieval_engine.retrieve(\"What is FinOps?\")\n",
        "print('-------------RAG-------------')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query engine**  \n",
        "data send to LLM as single-turn"
      ],
      "metadata": {
        "id": "GuKkClgwKcgp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2BZEAjzFQ9b",
        "outputId": "fb842ad0-7d9c-41d4-b10a-a4268f3d8049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------RAG-------------\n",
            "FinOps, or Cloud Financial Operations, is a strategic approach to managing cloud costs and resources. It involves analyzing, managing, and optimizing cloud usage to achieve cost efficiency and resource utilization. This includes forecasting costs, setting budgets, and monitoring usage to ensure that resources are being used effectively.\n",
            "\n",
            "The maturity of a FinOps practice can be divided into three stages: Crawl, Walk, and Run. \n",
            "\n",
            "1. Crawl: This is the initial stage\n"
          ]
        }
      ],
      "source": [
        "query_engine = load_index.as_query_engine(similarity_top_k = 5,llm=llm)\n",
        "response = query_engine.query(\"What is FinOps?\")\n",
        "print('-------------RAG-------------')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chat engine**  \n",
        "contain memory to perform multi-turn"
      ],
      "metadata": {
        "id": "OZ7c5qrMKfeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3kfK9F4FQ9b",
        "outputId": "0358908b-bcda-4cde-bede-87102dda4de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------RAG-------------\n",
            "FinOps, or Cloud Financial Operations, is a strategic approach to managing cloud costs and resources. It involves analyzing, managing, and optimizing cloud usage to ensure that organizations can use resources efficiently and cost-effectively. This includes understanding the costs of cloud services, monitoring usage, and making data-driven decisions to optimize spending. FinOps is not a one-size-fits-all approach. It\n"
          ]
        }
      ],
      "source": [
        "query_engine = load_index.as_chat_engine(similarity_top_k = 5,llm=llm)\n",
        "response = query_engine.chat(\"What is FinOps?\")\n",
        "print('-------------RAG-------------')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LTT1Xf7FQ9b",
        "outputId": "ac345ab7-00d5-4080-c91e-3379225ab02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------RAG-------------\n",
            "FinOps หรือ Cloud Financial Operations คือ แนวทางการจัดการค่าใช้จ่ายและทรัพยากรของคลาวด์คอมพิวติง โดยมีวัตถุประสงค์เพื่อให้องค์กรสามารถใช้ทรัพยากรได้อย่างมีประสิทธิภาพและประหยัดค่าใช้จ่าย การ FinOps ประกอบด้วยการวิเคราะห์ค่าใช้จ่ายของบริการค\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.chat(\"can you answer in thai language?\")\n",
        "print('-------------RAG-------------')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeleFGzCFQ9c"
      },
      "source": [
        "#### RAG  \n",
        "advance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VectorIndexRetriever** for using filter or hybrid search  \n",
        "**get_response_synthesizer** prompt template\n",
        "ResponseMode.COMPACT send request API **twice** for context and refine to get best answer\n",
        "SIMPLE_SUMMARIZE run only one time  \n",
        "**RetrieverQueryEngine**"
      ],
      "metadata": {
        "id": "_WX9MW9ON33P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVPQYAw5FQ9c",
        "outputId": "b0c1679c-7313-41db-f4f9-88af3eaf8ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FinOps, or Financial Operations, is a practice that focuses on managing cloud costs and optimizing the use of cloud resources. It involves a combination of people, processes, and technology to ensure that cloud spending aligns with business objectives. Here's a breakdown of what FinOps typically includes:\n",
            "\n",
            "1. **People (Personas):** FinOps involves various personas, each with their own roles and responsibilities. These include:\n",
            "   - **FinOps Practitioner:** Responsible for implementing FinOps practices within the organization.\n",
            "   - **Executive:** Responsible for providing strategic direction and ensuring alignment with business goals.\n",
            "   - **Business:** Responsible for understanding customer needs and ensuring the cloud solutions meet those needs.\n",
            "   - **Finance:** Responsible for managing the financial aspects of cloud spending.\n",
            "   - **Engineer:** Responsible for ensuring the technical feasibility of cloud solutions.\n",
            "\n",
            "2. **Processes:** FinOps involves a set of processes that help manage cloud costs. These include:\n",
            "   - **Inform:** This phase involves gathering data, setting up cost tracking, and forecasting future costs.\n",
            "   - **Optimize:** This phase involves analyzing data to identify areas of cost optimization and implementing changes to reduce costs.\n",
            "   - **Operate:** This phase involves ongoing monitoring and management of cloud costs.\n",
            "\n",
            "3. **Technology:** FinOps involves the use of various tools and technologies to manage cloud costs. These include:\n",
            "   - **Cloud Cost Management Tools:** These tools help track and analyze cloud costs.\n",
            "   - **Cloud Resource Management Tools:** These tools help manage and optimize the use of cloud resources.\n",
            "   - **Cloud Governance Tools:** These tools help ensure compliance with cloud policies and regulations.\n",
            "\n",
            "In summary, FinOps is a holistic approach to managing cloud costs that involves people, processes, and technology. It helps organizations ensure that their cloud spending aligns with their business objectives and maximizes the value they get from their cloud investments.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, get_response_synthesizer,load_index_from_storage,StorageContext\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngineg\n",
        "from llama_index.core.response_synthesizers.type import ResponseMode\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# configure LLMs\n",
        "\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "\n",
        "# build index\n",
        "load_index = load_index_from_storage(StorageContext.from_defaults(persist_dir='./localstore/'),embed_model=embed_model)\n",
        "\n",
        "\n",
        "# load_index.as_retriever()\n",
        "\n",
        "# configure retriever\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=load_index, # type: ignore\n",
        "    similarity_top_k=2,\n",
        ")\n",
        "\n",
        "# configure response synthesizer\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    response_mode=ResponseMode.SIMPLE_SUMMARIZE,\n",
        "    llm = llm\n",
        ")\n",
        "\n",
        "\n",
        "# assemble query engine\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")\n",
        "\n",
        "# query\n",
        "response = query_engine.query(\"FinOps ประกอบด้วยอะไรบ้าง?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting context_window  \n",
        "Settings.context_window = 4000  \n",
        "data will compress token to match context_window  \n",
        "Settings.tokenizer = tokenizer    \n",
        "need to set token like model"
      ],
      "metadata": {
        "id": "2MGDA_naPSBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l5VpFueFQ9d"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex,get_response_synthesizer\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SimpleFileNodeParser,TokenTextSplitter\n",
        "from llama_index.core import Settings\n",
        "from transformers import AutoTokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"SeaLLMs/SeaLLM-7B-v2\").encode\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "token_spliter = TokenTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=64,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "text_parser = SimpleFileNodeParser()\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "md_docs = FlatReader().load_data(Path(\"./MockupData/finops.md\"))\n",
        "md_nodes = token_spliter.get_nodes_from_documents(text_parser.get_nodes_from_documents(md_docs)) # type: ignore\n",
        "\n",
        "Settings.embed_model = embed_model\n",
        "Settings.llm = llm\n",
        "Settings.context_window = 4000\n",
        "Settings.tokenizer = tokenizer\n",
        "Settings.num_output = 512\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "      response_mode=\"simple_summarize\" # type: ignore\n",
        ")\n",
        "\n",
        "index = VectorStoreIndex(md_nodes)\n",
        "query_engine = index.as_query_engine(\n",
        "    llm=llm,\n",
        "    similarity_top_k = 10, #8000 token ; Expect 10 => 5 ; Actual 10 (100%) => 10 (50%)\n",
        "    response_synthesizer = response_synthesizer)\n",
        "response = query_engine.query(\"FinOps คืออะไร?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBUIYppyFQ9d",
        "outputId": "c9c53f92-9580-41b8-bfa0-a5ba0502858a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'FinOps (Cloud Financial Operations) คือการบริหารจัดการค่าใช้จ่ายและการใช้งานของคลาวด์คอมพิวติงในองค์กร โดยมีเป้าหมายเพื่อลดค่าใช้จ่ายที่ไม่จำเป็นและเพิ่มประสิทธิภาพการใช้งานคลาวด์ คำว่า FinOps มาจากคำว่า Financial Operations ซึ่งเป็นการบริหารจัดการด้านการเงินและการเงินในองค์กร โดย FinOps จะเน้นไปที่การบริหารจัดการค่าใช้จ่ายและการใช้งานคลาวด์คอมพิวติงในองค์กร\\n\\nFinOps Foundation เป็นองค์กรที่สนับสนุนการพัฒนาและส่งเสริมการใช้งาน FinOps ในองค์กร โดยมีเป้าหมายเพื่อช่วยให้องค์กรต่างๆ สามารถใช้งานคลาวด์คอมพิวติงได้อย่างมีประสิทธิภาพและมีค่าใช้จ่ายที่เหมาะสม\\n\\nการใช้งาน FinOps จะช่วยให้องค์กรสามารถติดตามและควบคุมการใช้งานคลาวด์ได้อย่างมีประสิทธิภาพ โดยการใช้เครื่องมือและแนวทางการทำงานที่เหมาะสม เพื่อให้สามารถตรวจสอบและจัดการค่าใช้จ่ายของคลาวด์ได้อย่างแม่นยำและมีประสิทธิภาพ\\n\\nการใช้งาน FinOps จะช่วยให้องค์กรสามารถลดค่าใช้จ่ายที่ไม่จำเป็นและเพิ่มประสิทธิภาพการใช้งานคลาวด์ได้ โดยการใช้เครื่องมือและแนวทางการทำงานที่เหมาะสม เพื่อให้สามารถตรวจสอบและจัดการค่าใช้จ่ายของคลาวด์ได้อย่างแม่นยำและมีประสิทธิภาพ'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.response # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yvxif6fFQ9e"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add tool function(multiply)"
      ],
      "metadata": {
        "id": "QfzzBIytQqX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6bmCUFCFQ9e",
        "outputId": "ba68d005-8479-4557-c704-41755a005cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
            "Action: multiply\n",
            "Action Input: {\"a\": 2123, \"b\": 111}\n",
            "\n",
            "Observation: 237033\n",
            "\n",
            "Thought: I can answer without using any more tools.\n",
            "Answer: 237033\n",
            "\u001b[0m237033\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.agent.react.formatter import ReActChatFormatter\n",
        "\n",
        "# define sample Tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "\n",
        "# initialize llm\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "\n",
        "# initialize ReAct agent\n",
        "agent = ReActAgent.from_tools([multiply_tool], llm=llm, verbose=True)\n",
        "res = agent.chat(\"What is 2123 * 111\")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "detail of prompt inside"
      ],
      "metadata": {
        "id": "U0P1woiaRGft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_03Z2sGhFQ9e",
        "outputId": "76f8f606-091b-477c-f517-413a844e8e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system: \n",
            "You are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\n",
            "\n",
            "## Tools\n",
            "You have access to a wide variety of tools. You are responsible for using\n",
            "the tools in any sequence you deem appropriate to complete the task at hand.\n",
            "This may require breaking the task into subtasks and using different tools\n",
            "to complete each subtask.\n",
            "\n",
            "You have access to the following tools:\n",
            "> Tool Name: multiply\n",
            "Tool Description: multiply(a: int, b: int) -> int\n",
            "Multiple two integers and returns the result integer\n",
            "Tool Args: {\"type\": \"object\", \"properties\": {\"a\": {\"title\": \"A\", \"type\": \"integer\"}, \"b\": {\"title\": \"B\", \"type\": \"integer\"}}, \"required\": [\"a\", \"b\"]}\n",
            "\n",
            "\n",
            "## Output Format\n",
            "To answer the question, please use the following format.\n",
            "\n",
            "```\n",
            "Thought: I need to use a tool to help me answer the question.\n",
            "Action: tool name (one of multiply) if using a tool.\n",
            "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
            "```\n",
            "\n",
            "Please ALWAYS start with a Thought.\n",
            "\n",
            "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
            "\n",
            "If this format is used, the user will respond in the following format:\n",
            "\n",
            "```\n",
            "Observation: tool response\n",
            "```\n",
            "\n",
            "You should keep repeating the above format until you have enough information\n",
            "to answer the question without using any more tools. At that point, you MUST respond\n",
            "in the one of the following two formats:\n",
            "\n",
            "```\n",
            "Thought: I can answer without using any more tools.\n",
            "Answer: [your answer here]\n",
            "```\n",
            "\n",
            "```\n",
            "Thought: I cannot answer the question with the provided tools.\n",
            "Answer: Sorry, I cannot answer your query.\n",
            "```\n",
            "\n",
            "## Current Conversation\n",
            "Below is the current conversation consisting of interleaving human and assistant messages.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = ReActChatFormatter().format(tools=[multiply_tool],chat_history=[])\n",
        "for i in prompt :\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDY7BXILFQ9f"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqFLP7BeFQ9f"
      },
      "source": [
        "#### Query Engine Tools  \n",
        "SubQuestionQueryEngine  \n",
        "distinguish question, answer two question, summary all answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYjn1aGuFQ9f"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex,StorageContext\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.vector_stores import SimpleVectorStore\n",
        "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
        "from llama_index.core.storage.index_store import SimpleIndexStore\n",
        "from pathlib import Path\n",
        "\n",
        "sentence_spilit = SentenceSplitter(\n",
        "    chunk_size=512\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=SimpleVectorStore(),\n",
        "    docstore=SimpleDocumentStore(),\n",
        "    index_store=SimpleIndexStore(),\n",
        ")\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "finops_docs = FlatReader().load_data(Path(\"./MockupData/finops.md\"))\n",
        "orbit_docs = FlatReader().load_data(Path(\"./MockupData/orbit.md\"))\n",
        "\n",
        "finops_nodes = sentence_spilit.get_nodes_from_documents(finops_docs)\n",
        "orbit_nodes = sentence_spilit.get_nodes_from_documents(orbit_docs)\n",
        "\n",
        "finops = VectorStoreIndex(finops_nodes,embed_model=embed_model,storage_context=storage_context)\n",
        "orbit = VectorStoreIndex(orbit_nodes,embed_model=embed_model,storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsJhVch6FQ9f"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "from llama_index.core.tools import QueryEngineTool,ToolMetadata\n",
        "\n",
        "# initialize llm\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "\n",
        "finops_engine = finops.as_query_engine(similarity_top_k=3,llm=llm)\n",
        "orbit_engine = orbit.as_query_engine(similarity_top_k=3, llm=llm)\n",
        "\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=finops_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"finops\",\n",
        "            description=\"ข้อมูลเกี่ยวกับแนวคิดของ Finops\",\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=orbit_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"orbit\",\n",
        "            description=\"ข้อมูลเกี่ยวกับแนวคิดของ Orbit\",\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "sub_query_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools, llm=llm, verbose=True,use_async=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiUQSv6gFQ9g",
        "outputId": "f1c48d38-5ee0-428b-8a91-44beb0f0fa2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 2 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[finops] Q: What is Finops\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[orbit] Q: What is Orbit\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[finops] A: FinOps, or cloud financial operations, is a framework and set of best practices for managing and optimizing cloud costs. It's a collaborative effort between finance, IT, and lines of business to manage cloud resources and costs. The goal of FinOps is to ensure that cloud resources are used efficiently and cost-effectively, while also providing visibility and control over cloud spending.\n",
            "\n",
            "FinOps involves several key elements, including cost allocation, cost optimization, and cost governance. It also involves understanding the cost drivers of cloud usage, such as usage patterns, resource utilization, and pricing models.\n",
            "\n",
            "The FinOps Foundation, which is supported by The Linux Foundation, aims to promote the adoption and advancement of FinOps practices. It provides a community for practitioners to share knowledge, best practices, and tools.\n",
            "\n",
            "In summary, FinOps is a strategic approach to managing cloud costs, ensuring that organizations are getting the most value from their cloud investments.\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[orbit] A: Orbit Model is a framework or model used to measure and understand the level of engagement and impact of individuals within a community or organization. It is designed to help community managers and creators enhance diversity and improve the effectiveness of their communities. This model is particularly useful for creating high gravity communities, where \"gravity\" represents the level of involvement of community members.\n",
            "\n",
            "The Orbit Model consists of four key concepts:\n",
            "\n",
            "1. Gravity: This represents the level of involvement of community members, measured at the community level.\n",
            "2. Love: This indicates the individual level of engagement of community members.\n",
            "3. Reach: This refers to the size of the impact that community members have on the success of the community.\n",
            "4. Impact: This represents the outcomes or results that are achieved through the community's activities.\n",
            "\n",
            "The model emphasizes the importance of activities and the perception of the community, and it categorizes various types of activities into different groups, each with a weight that indicates the level of responsibility and involvement in the community. Examples of activities include participation, posting in forums, giving presentations, organizing events, answering questions, opening pull requests on platforms like GitHub, writing blog posts, donating, and expressing gratitude.\n",
            "\n",
            "Each activity has a weight that reflects the level of engagement and contribution to the community. For instance, organizing events is considered a high-commitment activity with a weight of 11.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "res = sub_query_engine.query('finops และ orbit แตกต่างกันอย่างไร')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvZ_oe24FQ9g",
        "outputId": "0eec39d2-b902-42a1-a7cf-f78c4e917024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"FinOps and Orbit are two distinct concepts that serve different purposes.\\n\\nFinOps, or cloud financial operations, is a framework and set of best practices for managing and optimizing cloud costs. It's a collaborative effort between finance, IT, and lines of business to manage cloud resources and costs. The goal of FinOps is to ensure that cloud resources are used efficiently and cost-effectively, while also providing visibility and control over cloud spending.\\n\\nOn the other hand, Orbit Model is a framework or model used to measure and understand the level of engagement and impact of individuals within a community or organization. It is designed to help community managers and creators enhance diversity and improve the effectiveness of their communities.\\n\\nIn summary, FinOps is a strategic approach to managing cloud costs, ensuring that organizations are getting the most value from their cloud investments, while Orbit Model is a framework to measure and understand the level of engagement and impact of individuals within a community or organization.\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMtuKCNlFQ9g",
        "outputId": "df00eea3-a79c-44a8-fcd8-e99001dfe495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 2 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[finops] Q: Finops คืออะไร\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[orbit] Q: Orbit คืออะไร\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[orbit] A: Orbit Model เป็นกรอบการทำงานที่ใช้ในการสร้างชุมชนที่มีอัตราการมีส่วนร่วมสูง (high gravity communities) โดยเน้นการสร้างประสบการณ์สมาชิกที่โดดเด่นและเสริมสร้างความสัมพันธ์ระหว่างสมาชิกในชุมชน\n",
            "\n",
            "โมเดลนี้แบ่งออกเป็นสี่แนวคิดหลัก ได้แก่ \"Gravity\" (อัตราการมีส่วนร่วมของสมาชิกที่วัดที่ระดับของชุมชน), \"Love\" (การมีส่วนร่วมของสมาชิกรายบุคคล), \"Reach\" (ขนาดของผลกระทบที่สมาชิกมีต่อความสำเร็จของชุมชน), และ \"Impact\" (ผลลัพธ์ที่เกิดขึ้นจากการดำเนินการ).\n",
            "\n",
            "Orbit Model เน้นการวัดและเข้าใจกิจกรรมต่างๆ ที่สมาชิกมีส่วนร่วมในชุมชน โดยแบ่งประเภทกิจกรรมต่าง ๆ ออกเป็นกลุ่มต่าง ๆ โดยมีน้ำหนักที่บ่งบอกระดับความรับผิดชอบและการมีส่วนร่วมในชุมชน ตัวอย่างของกิจกรรมเช่น การเข้าร่วม, การโพสต์ในฟอรัม, การนำเสนอ, การจัดการพบปะ, การถาม-ตอบคำถาม, การเปิด pull request ในแพลตฟอร์มเช่น GitHub, การเขียนบทความบล็อก, การบริจาค, และการส่งคำขอบคุณ.\n",
            "\n",
            "โมเดลนี้เป็นเครื่องมือที่มีประสิทธิภาพสำหรับผู้จัดการและผู้สร้างชุมชน เพื่อเสริมความหลากหลายและเพิ่มประสิทธิภาพของชุมชน และช่วยให้สามารถวัดและเข้าใจความมีส่วนร่วมและผลกระทบของสมาชิกและสนับสนุนสมาชิกได้อย่างมีประสิทธิภาพมากยิ่งขึ้น.\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[finops] A: FinOps (Cloud Financial Operations) เป็นโครงการที่ได้รับการสนับสนุนจาก The Linux Foundation เพื่อช่วยสร้างโครงสร้างพื้นฐานที่สนับสนุนการใช้งาน Cloud computing อย่างมีคุณค่า. มันถูกสร้างขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) และถือว่าเป็นโครงสร้างพื้นฐานที่อายุน้อยมาก (เทียบกับปี 2023).\n",
            "\n",
            "FinOps มีวัตถุประสงค์เพื่อช่วยให้บริษัทสามารถจัดการกับการใช้จ่ายใน Cloud computing ได้อย่างมีประสิทธิภาพ โดยการสร้างกระบวนการทำงานและรายงานผลที่มีประสิทธิภาพ. มันช่วยให้ทีมต่างๆ เช่น ทีม Engineer, ทีม Finance, และทีม Procurement สามารถทำงานร่วมกันได้อย่างมีประสิทธิภาพ.\n",
            "\n",
            "FinOps ยังมีแนวคิดเกี่ยวกับ \"Maturity\" ซึ่งแบ่งออกเป็น 3 ช่วง ได้แก่ Crawl, Walk, และ Run. ช่วง Crawl คือช่วงเริ่มต้นของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง. ช่วง Walk คือช่วงของการทำงานที่มีความซับซ้อนมากขึ้นและมีการใช้งานระบบอัตโนมัติ. ช่วง Run คือช่วงที่การทำงานเป็นไปอย่างราบรื่นและมีประสิทธิภาพ.\n",
            "\n",
            "นอกจากนี้ FinOps ยังมี \"Personas\" หรือบุคคลที่เกี่ยวข้องกับการใช้งาน FinOps ซึ่งรวมถึง FinOps Practitioner, Executive, Business, Finance, และ Engineer. แต่ละบุคคลมีแรงจูงใจ, ปัญหา, ตัวชี้วัด, และสิ่งที่ได้จาก FinOps ที่แตกต่างกัน.\n",
            "\n",
            "โดยรวมแล้ว FinOps เป็นกระบวนการที่ช่วยให้บริษัทสามารถจัดการกับการใช้จ่ายใน Cloud computing ได้อย่างมีประสิทธิภาพและเป็นไปตามหลักการธุรกิจ.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "res = sub_query_engine.query('finops คืออะไร')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMCF0mFUFQ9g",
        "outputId": "c99c9373-dec9-4323-fde9-bd2eca192cea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'FinOps (Cloud Financial Operations) เป็นโครงการที่ได้รับการสนับสนุนจาก The Linux Foundation เพื่อช่วยสร้างโครงสร้างพื้นฐานที่สนับสนุนการใช้งาน Cloud computing อย่างมีคุณค่า. มันถูกสร้างขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) และถือว่าเป็นโครงสร้างพื้นฐานที่อายุน้อยมาก (เทียบกับปี 2023).\\n\\nFinOps มีวัตถุประสงค์เพื่อช่วยให้บริษัทสามารถจัดการกับการใช้จ่ายใน Cloud computing ได้อย่างมีประสิทธิภาพ โดยการสร้างกระบวนการทำงานและรายงานผลที่มีประสิทธิภาพ. มันช่วยให้ทีมต่างๆ เช่น ทีม Engineer, ทีม Finance, และทีม Procurement สามารถทำงานร่วมกันได้อย่างมีประสิทธิภาพ.\\n\\nFinOps ยังมีแนวคิดเกี่ยวกับ \"Maturity\" ซึ่งแบ่งออกเป็น 3 ช่วง ได้แก่ Crawl, Walk, และ Run. ช่วง Crawl คือช่วงเริ่มต้นของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง. ช่วง Walk คือช่วงของการทำงานที่มีความซับซ้อนมากขึ้นและมีการใช้งานระบบอัตโนมัติ. ช่วง Run คือช่วงที่การทำงานเป็นไปอย่างราบรื่นและมีประสิทธิภาพ.\\n\\nนอกจากนี้ FinOps ยังมี \"Personas\" หรือบุคคลที่เกี่ยวข้องกับการใช้งาน FinOps ซึ่งรวมถึง FinOps Practitioner, Executive, Business, Finance, และ Engineer. แต่ละบุคคลมีแรงจูงใจ, ปัญหา, ตัวชี้วัด, และสิ่งที่ได้จาก FinOps ที่แตกต่างกัน.\\n\\nโดยรวมแล้ว FinOps เป็นกระบวนการที่ช่วยให้บริษัทสามารถจัดการกับการใช้จ่ายใน Cloud computing ได้อย่างมีประสิทธิภาพและเป็นไปตามหลักการธุรกิจ.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRWTl61FUm0"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-as-a-Judge FaithfulnessEvaluator judge llm shouldn't be the same as test_llm"
      ],
      "metadata": {
        "id": "T_oO32tMFD3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVaH31JfFUm3",
        "outputId": "b2a42d0a-9787-476e-cb6b-b944b9fbc312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.vector_stores import SimpleVectorStore\n",
        "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
        "from llama_index.core.storage.index_store import SimpleIndexStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "from llama_index.core import VectorStoreIndex,StorageContext\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from pathlib import Path\n",
        "\n",
        "# initialize llm\n",
        "test_llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"SeaLLMs/SeaLLM-7B-v2\", token=HF_TOKEN\n",
        ")\n",
        "\n",
        "sentence_spilit = SentenceSplitter(\n",
        "    chunk_size=1024\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=SimpleVectorStore(),\n",
        "    docstore=SimpleDocumentStore(),\n",
        "    index_store=SimpleIndexStore(),\n",
        ")\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\",device='cpu')\n",
        "finops_docs = FlatReader().load_data(Path(\"./MockupData/finops.md\"))\n",
        "\n",
        "finops_nodes = sentence_spilit.get_nodes_from_documents(finops_docs)\n",
        "\n",
        "# create llm\n",
        "llm = OpenAI(model=\"gpt-4-1106-preview\", temperature=0.0)\n",
        "\n",
        "# build index\n",
        "finops_index = VectorStoreIndex(finops_nodes,embed_model=embed_model,storage_context=storage_context)\n",
        "\n",
        "# define evaluator\n",
        "evaluator = FaithfulnessEvaluator(llm=llm)\n",
        "\n",
        "# query index\n",
        "query_engine = finops_index.as_query_engine(llm=test_llm)\n",
        "response = query_engine.query(\n",
        "    \"FinOps คืออะไร?\"\n",
        ")\n",
        "eval_result = evaluator.evaluate_response(response=response) # type: ignore\n",
        "print(str(eval_result.passing))\n",
        "print(eval_result.score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Retriever"
      ],
      "metadata": {
        "id": "OnxvNjitFg0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MRR (Mean Reciprocal Rank): The Mean Reciprocal Rank is a metric used to evaluate the effectiveness of a retrieval system based on its ability to return relevant documents. Specifically, it calculates the average of the reciprocal ranks of the first relevant document for a set of queries. The rank is the position of the first relevant document in the list of retrieved documents. The reciprocal rank is the inverse of this position (i.e., 1 divided by the rank). The MRR is the mean (average) of these reciprocal ranks across all queries. This metric is particularly useful when you are interested in the rank of the first relevant result. MRR values range from 0 to 1, where higher values indicate better performance."
      ],
      "metadata": {
        "id": "Ogkf1wqvHV-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hit Rate: Hit Rate is a simpler metric that measures the percentage of queries for which at least one relevant document is retrieved. It's a way to assess the system's ability to retrieve relevant information across a number of queries. Essentially, it checks if a relevant document is present in the retrieved set, without concern for the rank of that document. The Hit Rate is calculated as the number of queries with at least one relevant document retrieved divided by the total number of queries, often expressed as a percentage. Like MRR, higher values of Hit Rate indicate better performance of the retrieval system."
      ],
      "metadata": {
        "id": "-ajKNYJRIKCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Both MRR and Hit Rate are crucial for evaluating the performance of retrieval systems in different contexts. MRR provides insight into the quality of the top-ranked results, emphasizing the importance of ranking relevant documents higher, while Hit Rate gives a broader view of the system's overall ability to retrieve relevant information, regardless of its rank."
      ],
      "metadata": {
        "id": "_9DiVoXyILfc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--KNtjjRFUm4"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "\n",
        "retriever = finops_index.as_retriever()\n",
        "\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        ")\n",
        "\n",
        "res = retriever_evaluator.evaluate(\n",
        "    query=\"finops คืออะไร ?\" ,expected_ids=['node_id1']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0oeoI1SFUm5",
        "outputId": "093fbaca-9524-4060-a524-2e5b3b700cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RetrievalEvalResult(query='finops คืออะไร ?', expected_ids=['node_id1'], expected_texts=None, retrieved_ids=['c23f04c7-9de6-494e-8046-74bb5997cdd6', '719e6b74-4686-4152-903f-cd03c6b081c1'], retrieved_texts=['II FinOps ?  \\nA FinOps (cloud Financial Operations)\\nFinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\\n\\nB History\\nFinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\\nIII Cloud in real life  \\nการใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\\nA Spending decision\\nความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud environment เรียบร้อยแล้ว คนที่เข้าใจ Cloud มากที่สุดกลับเป็นทีม Engineer ที่ไม่มีหน้าที่ในการรับผิดชอบการใช้จ่ายของบริษัท หรือเมื่อ Spending decision ยังอยู่กับทีม Financial คนที่ต้อง Commit รายจ่ายของ Cloud computing ก็ยังคงเป็นทีม Engineer\\n\\nถ้าไม่แก้ไขปัญหาจากเหตุการณ์ดังกล่าวจะเกิดเหตุการณ์ Engineer Commit รายจ่ายให้สูงเกินความจำเป็น หรือ การใช้งานบางอย่าง (Serverless) ส่งผลให้เกิดรายจ่ายที่ผิดปกติในเดือนนั้น ๆ', 'เครื่องมือ, กิจกรรม, ความเข้ากันได้ หรือ สิ่งขับเคลื่อน ซึ่งแต่ละหัวข้อสามารถแยกพิจารณาเมื่อไหร่ก็ได้ ไม่จำเป็นต้องเรียงลำดับและในแต่ละบริษัทไม่จำที่จะต้องให้น้ำหนักกับแต่ละหัวข้อเหมือนกันทุกบริษัท ขึ้นอยู่กับบริบทของบริษัทนั้น ๆ\\n\\nเราขอเริ่มอธิบายจากหัวข้อแรก\\n\\nA Maturity\\nMaturity เราอาจจะเรียกได้ว่าเป็นประสบการณ์ของทีม แต่ในที่นี้ขอเรียกว่าความเข้ากันได้ เนื่องจากบางบริษัททีมมีความเข้ากันได้อยู่แล้ว เคยทำงานร่วมกันด้วยความเข้าใจดีเยี่ยม ความเข้ากันได้ของทีมนั้น ๆ ก็จะสูงตาม\\n\\nในบริบทของ FinOps เราแบ่ง Maturity ออกเป็น 3 ช่วง ได้แก่\\n\\nCrawl\\nช่วงแรกเริ่มของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง ซึ่งเราสามารถประเมินได้ว่าบริษัทที่อยู่ในช่วงดังกล่าวได้ว่า กระบวนการทำงาน, กระบวนการรายงานผล ยังอยู่ในรูปแบบของ Manual หรือไม่ได้ใช้ระบบอัตโนมัติเข้ามาช่วย รวมถึงการทำงานบางส่วน เช่น Forecast ค่าใช้จ่าย ยังคงต้องคำนวนใหม่ทุกครั้ง ยังไม่ได้สร้างสูตรหรือโมเดลในการช่วยคำนวน ต้องให้ทีม Finance ประเมินทุก ๆ คร้ัง\\n\\nWalk\\nบางบริษัทอาจจะเริ่มจากช่วงนี้เลยก็เป็นไปได้ สำหรับช่วง walk นั้นจะเรียกได้ว่าเป็นช่วงของ Semi-Automate process เนื่องจากทีมมีบุคคลที่มีความสามารถในการสร้าง Automate process ด้วยตัวเอง ไม่ว่าจะเป็นทีม Engineer,'], mode=<RetrievalEvalMode.TEXT: 'text'>, metric_dict={'mrr': RetrievalMetricResult(score=0.0, metadata={}), 'hit_rate': RetrievalMetricResult(score=0.0, metadata={})})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rX7_zRuoUgXm",
        "Qs6tnBL9N_uh",
        "8RVWCnPXEQ3c",
        "DOttCBP5pNRi",
        "BNqkdDB3FCyS",
        "SEJ6XDlPE5ar",
        "3bLGPxi2E5aw",
        "edai5XUOE99j",
        "bkruJPbQFI44",
        "yyURAzD5FNXr",
        "kIRWTl61FUm0"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}